{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Models.Layers import *\n",
    "from Solver import *\n",
    "from Models.Classifiers.Logistic_Classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>percentage_free_sulphur</th>\n",
       "      <th>n_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>30.909091</td>\n",
       "      <td>0.6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>0.8290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.7440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>0.7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>30.909091</td>\n",
       "      <td>0.6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.076923</td>\n",
       "      <td>0.7110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.6615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>1.2075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  percentage_free_sulphur  n_value  \n",
       "0         9.4        0                30.909091   0.6080  \n",
       "1         9.8        0                26.800000   0.8290  \n",
       "2         9.8        0                36.000000   0.7440  \n",
       "3         9.8        1                35.294118   0.7195  \n",
       "4         9.4        0                30.909091   0.6080  \n",
       "...       ...      ...                      ...      ...  \n",
       "1594     10.5        0                13.750000   0.6610  \n",
       "1595     11.2        1                13.076923   0.7110  \n",
       "1596     11.0        1                13.793103   0.7540  \n",
       "1597     10.2        0                13.750000   0.6615  \n",
       "1598     11.0        1                23.333333   1.2075  \n",
       "\n",
       "[1599 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first step would be to import the dataset\n",
    "X_full = pd.read_csv('./Datasets/red_wine_dataset.csv')\n",
    "percentage = 0.8\n",
    "X_full.pop('k_value')\n",
    "X_full.pop('l_value')\n",
    "X_full.pop('m_value')\n",
    "X_train = X_full.sample(frac=percentage, random_state=0)\n",
    "y_train = X_train.pop('quality')\n",
    "X_test = X_full.drop(X_train.index)\n",
    "y_test = X_test.pop('quality')\n",
    "print(len(X_train.index))\n",
    "print(len(X_test.index))\n",
    "X_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 13)\n",
      "(320, 13)\n",
      "float64\n",
      "(1279,)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.to_numpy()\n",
    "x_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_train.dtype)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 13)\n",
      "(1279,)\n",
      "0.12433391471702653\n",
      "0.10003662221022867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_max = np.max(x_train, axis = 0)\n",
    "x_min = np.min(x_train, axis = 0)\n",
    "x_train = (x_train - x_min) / (x_max - x_min)\n",
    "mu = x_min\n",
    "sigma = (x_max - x_min)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, s=50, cmap='spring')\n",
    "print(x_train[:,3].mean())\n",
    "print(x_train[:,3].std())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet():\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, reg = 0.01):\n",
    "        self.reg = reg\n",
    "        self.params = {}\n",
    "        # Now we do intialization of the weights\n",
    "        np.random.seed(0)\n",
    "        self.params['W'] = np.random.randn(input_dim, hidden_dim)*0.1\n",
    "        self.params['b'] = np.zeros(hidden_dim)\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def loss(self,X,y = None):\n",
    "        # define a mode here, i.e. a training mode or a test mode\n",
    "        mode = 'test' if y is None else 'train'\n",
    "        if(mode == 'train'):\n",
    "            cache = {}\n",
    "            loss = 0\n",
    "            grads = {}\n",
    "            z1, cache['affine'] = affine_forward(X,self.params['W'],self.params['b'])\n",
    "            a1,cache['relu'] = relu_forward(z1)\n",
    "            loss, da1 = softmax_loss(a1,y)\n",
    "            dz1 = relu_backward(da1,cache['relu'])\n",
    "            grads['x'],grads['W'],grads['b'] = affine_backward(dz1,cache['affine'])\n",
    "            loss = loss + self.reg * np.sum(self.params['W'] * self.params['W'])\n",
    "            grads['W'] = grads['W'] + 2 * self.reg * self.params['W']\n",
    "            return loss, grads\n",
    "        else:\n",
    "            z1, cache['affine'] = affine_forward(X,self.params['W'],self.params['b'])\n",
    "            a1,cache['relu'] = relu_forward(z1)\n",
    "            loss, da1 = softmax_loss(a1,y)\n",
    "            loss = loss + self.reg * np.sum(self.params['W'] * self.params['W'])\n",
    "            return loss\n",
    "    def predict(self, X):\n",
    "        cache= {}\n",
    "        z1, cache['affine'] = affine_forward(X,self.params['W'],self.params['b'])\n",
    "        scores,cache['relu'] = relu_forward(z1)\n",
    "        return np.argmax(scores,axis = 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2.338015998274456\n",
      "loss after change = 2.2853082353772467\n"
     ]
    }
   ],
   "source": [
    "Model = TwoLayerNet(input_dim = x_train.shape[1], hidden_dim = 10, output_dim = 3)\n",
    "\n",
    "loss, grads = Model.loss(x_train, y_train)\n",
    "\n",
    "print(\"loss =\", loss)\n",
    "\n",
    "Model.params['W'] = Model.params['W'] - 0.1*grads['W']\n",
    "Model.params['b'] = Model.params['b'] - 0.1*grads['b']\n",
    "\n",
    "loss, grads = Model.loss(x_train, y_train)\n",
    "print(\"loss after change =\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 Batch =  0 Loss =  68.06390774470488 Gradient_max =  0.41542300114804726 learning rate ratio =  0.00424123846113326\n",
      "Epoch =  1 Batch =  0 Loss =  67.90014509715552 Gradient_max =  0.4149832193235019 learning rate ratio =  0.0002561227944009972\n",
      "Epoch =  2 Batch =  0 Loss =  67.68551392681577 Gradient_max =  0.41442718012153196 learning rate ratio =  0.0002835959171094992\n",
      "Epoch =  3 Batch =  0 Loss =  67.46234770393194 Gradient_max =  0.41387067505053277 learning rate ratio =  0.0003172719487685675\n",
      "Epoch =  4 Batch =  0 Loss =  67.23557315332673 Gradient_max =  0.41331342970030516 learning rate ratio =  0.0003586307535035876\n",
      "Epoch =  5 Batch =  0 Loss =  67.0066410015432 Gradient_max =  0.4127547741572475 learning rate ratio =  0.00041089126296630263\n",
      "Epoch =  6 Batch =  0 Loss =  66.77137625032292 Gradient_max =  0.41219679023469236 learning rate ratio =  0.0004782710295911457\n",
      "Epoch =  7 Batch =  0 Loss =  66.52088829236503 Gradient_max =  0.41164396335508363 learning rate ratio =  0.000539191909880906\n",
      "Epoch =  8 Batch =  0 Loss =  66.26564540334823 Gradient_max =  0.4175198312830106 learning rate ratio =  0.0006606382692470488\n",
      "Epoch =  9 Batch =  0 Loss =  66.00506665087559 Gradient_max =  0.4170536430195443 learning rate ratio =  0.0008489108352202791\n",
      "Epoch =  10 Batch =  0 Loss =  65.74324759650314 Gradient_max =  0.41657580015613743 learning rate ratio =  0.0011767239507124764\n",
      "Epoch =  11 Batch =  0 Loss =  65.48159253921882 Gradient_max =  0.41609221293301646 learning rate ratio =  0.0018735036785850984\n",
      "Epoch =  12 Batch =  0 Loss =  65.21992499402651 Gradient_max =  0.41560200952259957 learning rate ratio =  0.0041306954539333\n",
      "Epoch =  13 Batch =  0 Loss =  64.95852140814009 Gradient_max =  0.41510613421083536 learning rate ratio =  8.810313999547004e-05\n",
      "Epoch =  14 Batch =  0 Loss =  64.69781875309606 Gradient_max =  0.41460624601238144 learning rate ratio =  9.148496460731814e-05\n",
      "Epoch =  15 Batch =  0 Loss =  64.43780193820731 Gradient_max =  0.41410245038449084 learning rate ratio =  9.568286165068747e-05\n",
      "Epoch =  16 Batch =  0 Loss =  64.17898436686842 Gradient_max =  0.41359679585782244 learning rate ratio =  0.00010029013857806863\n",
      "Epoch =  17 Batch =  0 Loss =  63.9211509476418 Gradient_max =  0.4130884401564601 learning rate ratio =  0.0001053923039478039\n",
      "Epoch =  18 Batch =  0 Loss =  63.66438793729397 Gradient_max =  0.4125778672174632 learning rate ratio =  0.00011105636963111005\n",
      "Epoch =  19 Batch =  0 Loss =  63.40874227434284 Gradient_max =  0.41206508074105586 learning rate ratio =  0.00011738140729480241\n",
      "Epoch =  20 Batch =  0 Loss =  63.154164568135606 Gradient_max =  0.41155009466989506 learning rate ratio =  0.00012448704832588087\n",
      "Epoch =  21 Batch =  0 Loss =  62.90055780026225 Gradient_max =  0.4110324867614762 learning rate ratio =  0.00013254328312157452\n",
      "Epoch =  22 Batch =  0 Loss =  62.64802055622982 Gradient_max =  0.41051260115110627 learning rate ratio =  0.00014174357966076478\n",
      "Epoch =  23 Batch =  0 Loss =  62.396747871591415 Gradient_max =  0.4099908744190245 learning rate ratio =  0.00015233922284099214\n",
      "Epoch =  24 Batch =  0 Loss =  62.146586582386114 Gradient_max =  0.4094672383119814 learning rate ratio =  0.00016466297038873737\n",
      "Epoch =  25 Batch =  0 Loss =  61.897594352208976 Gradient_max =  0.40894182403086843 learning rate ratio =  0.00017917521958821643\n",
      "Epoch =  26 Batch =  0 Loss =  61.64972901060399 Gradient_max =  0.4084145713939069 learning rate ratio =  0.00019651590939067645\n",
      "Epoch =  27 Batch =  0 Loss =  61.40300210602243 Gradient_max =  0.4078855269451965 learning rate ratio =  0.00021760150453167053\n",
      "Epoch =  28 Batch =  0 Loss =  61.15753427529432 Gradient_max =  0.4073549809129396 learning rate ratio =  0.00024379239567847604\n",
      "Epoch =  29 Batch =  0 Loss =  60.91325089802449 Gradient_max =  0.4068228258993985 learning rate ratio =  0.00027719847529080914\n",
      "Epoch =  30 Batch =  0 Loss =  60.670076389053705 Gradient_max =  0.4062888790507544 learning rate ratio =  0.0003212780029397911\n",
      "Epoch =  31 Batch =  0 Loss =  60.42802885296945 Gradient_max =  0.40575320810782184 learning rate ratio =  0.00038211977268083847\n",
      "Epoch =  32 Batch =  0 Loss =  60.18713130852625 Gradient_max =  0.40521589406431435 learning rate ratio =  0.00047153119748331943\n",
      "Epoch =  33 Batch =  0 Loss =  59.947395489448006 Gradient_max =  0.4046769757937169 learning rate ratio =  0.0006158118750739794\n",
      "Epoch =  34 Batch =  0 Loss =  59.70883770355992 Gradient_max =  0.4041364880502587 learning rate ratio =  0.0008878310977732863\n",
      "Epoch =  35 Batch =  0 Loss =  59.47147641228202 Gradient_max =  0.4035944812474479 learning rate ratio =  0.0015919834584827838\n",
      "Epoch =  36 Batch =  0 Loss =  59.23527778694907 Gradient_max =  0.4030509175357391 learning rate ratio =  0.007734719757757402\n",
      "Epoch =  37 Batch =  0 Loss =  59.00018388497014 Gradient_max =  0.4025057138350182 learning rate ratio =  0.0007525861481304236\n",
      "Epoch =  38 Batch =  0 Loss =  58.766203629891834 Gradient_max =  0.40195890654628047 learning rate ratio =  0.001106224608992752\n",
      "Epoch =  39 Batch =  0 Loss =  58.53333513359533 Gradient_max =  0.4014105196888056 learning rate ratio =  0.0020895561076528187\n",
      "Epoch =  40 Batch =  0 Loss =  58.30157720146982 Gradient_max =  0.40086057148613574 learning rate ratio =  0.019036603133982803\n",
      "Epoch =  41 Batch =  0 Loss =  58.07094181954332 Gradient_max =  0.40030911300873584 learning rate ratio =  0.0014450281920315\n",
      "Epoch =  42 Batch =  0 Loss =  57.841446694593294 Gradient_max =  0.3997562122165439 learning rate ratio =  0.003307145587368401\n",
      "Epoch =  43 Batch =  0 Loss =  57.61309856805374 Gradient_max =  0.39920191204363714 learning rate ratio =  0.00026444613308510917\n",
      "Epoch =  44 Batch =  0 Loss =  57.38586191683008 Gradient_max =  0.3986461581585896 learning rate ratio =  0.00029595086540137394\n",
      "Epoch =  45 Batch =  0 Loss =  57.159745422229676 Gradient_max =  0.3980889939528154 learning rate ratio =  0.00033603585381668645\n",
      "Epoch =  46 Batch =  0 Loss =  56.93474783906095 Gradient_max =  0.3975304413636769 learning rate ratio =  0.00038875951649607906\n",
      "Epoch =  47 Batch =  0 Loss =  56.71091543169306 Gradient_max =  0.3969706339743693 learning rate ratio =  0.0004612189149300824\n",
      "Epoch =  48 Batch =  0 Loss =  56.488250679682835 Gradient_max =  0.39640962055963114 learning rate ratio =  0.0005670481984767914\n",
      "Epoch =  49 Batch =  0 Loss =  56.26676241775317 Gradient_max =  0.39584743416889234 learning rate ratio =  0.0007361971610969882\n",
      "Epoch =  50 Batch =  0 Loss =  56.04642805973997 Gradient_max =  0.3952840650386005 learning rate ratio =  0.0010497550314324893\n",
      "Epoch =  51 Batch =  0 Loss =  55.827209302818304 Gradient_max =  0.3947194476610304 learning rate ratio =  0.0018304018254308876\n",
      "Epoch =  52 Batch =  0 Loss =  55.60914127335208 Gradient_max =  0.3941536877638681 learning rate ratio =  0.007168372714683286\n",
      "Epoch =  53 Batch =  0 Loss =  55.39217795788532 Gradient_max =  0.3935867075416611 learning rate ratio =  0.00015297815348046094\n",
      "Epoch =  54 Batch =  0 Loss =  55.17630769593043 Gradient_max =  0.39301850456900334 learning rate ratio =  0.00016256560150450353\n",
      "Epoch =  55 Batch =  0 Loss =  54.96160814265209 Gradient_max =  0.39244934162969686 learning rate ratio =  0.0001734516809658813\n",
      "Epoch =  56 Batch =  0 Loss =  54.74805313642395 Gradient_max =  0.39187915301432386 learning rate ratio =  0.00018591949423835545\n",
      "Epoch =  57 Batch =  0 Loss =  54.535632404907574 Gradient_max =  0.39130792641293854 learning rate ratio =  0.0002003409171057727\n",
      "Epoch =  58 Batch =  0 Loss =  54.324371608001535 Gradient_max =  0.39073579180927415 learning rate ratio =  0.00021721434574303256\n",
      "Epoch =  59 Batch =  0 Loss =  54.11426652736674 Gradient_max =  0.3901627520228778 learning rate ratio =  0.00023722337699611402\n",
      "Epoch =  60 Batch =  0 Loss =  53.90533227578771 Gradient_max =  0.38958892128649997 learning rate ratio =  0.00026133184440287006\n",
      "Epoch =  61 Batch =  0 Loss =  53.69752407613956 Gradient_max =  0.38901412899314247 learning rate ratio =  0.000290943618764083\n",
      "Epoch =  62 Batch =  0 Loss =  53.49084752347113 Gradient_max =  0.38843837565092926 learning rate ratio =  0.0003281862270729103\n",
      "Epoch =  63 Batch =  0 Loss =  53.285297828698766 Gradient_max =  0.38786174749913166 learning rate ratio =  0.0003764457430540819\n",
      "Epoch =  64 Batch =  0 Loss =  53.08084285986724 Gradient_max =  0.38728421086137726 learning rate ratio =  0.0004414596434998063\n",
      "Epoch =  65 Batch =  0 Loss =  52.87746772047001 Gradient_max =  0.386705765235687 learning rate ratio =  0.0005337863753204135\n",
      "Epoch =  66 Batch =  0 Loss =  52.675172030323765 Gradient_max =  0.3861264399086477 learning rate ratio =  0.0006752154532254056\n",
      "Epoch =  67 Batch =  0 Loss =  52.473963882265274 Gradient_max =  0.3855462987742917 learning rate ratio =  0.0009191101349504084\n",
      "Epoch =  68 Batch =  0 Loss =  52.27384338736976 Gradient_max =  0.3849653747376186 learning rate ratio =  0.0014400819664096012\n",
      "Epoch =  69 Batch =  0 Loss =  52.07479487487204 Gradient_max =  0.3843836484644215 learning rate ratio =  0.003331191832517813\n",
      "Epoch =  70 Batch =  0 Loss =  51.876818985562004 Gradient_max =  0.38380115346893 learning rate ratio =  0.0002489132832506561\n",
      "Epoch =  71 Batch =  0 Loss =  51.679913642643704 Gradient_max =  0.3832179171124568 learning rate ratio =  0.00028253297545357604\n",
      "Epoch =  72 Batch =  0 Loss =  51.484111614047784 Gradient_max =  0.38263404621663405 learning rate ratio =  0.00032672687671590956\n",
      "Epoch =  73 Batch =  0 Loss =  51.289401508104284 Gradient_max =  0.3820495508865828 learning rate ratio =  0.0003874151956403591\n",
      "Epoch =  74 Batch =  0 Loss =  51.095783378123734 Gradient_max =  0.3814644663190142 learning rate ratio =  0.0004759516398663739\n",
      "Epoch =  75 Batch =  0 Loss =  50.903290493473996 Gradient_max =  0.3808788451320162 learning rate ratio =  0.0006172128203452113\n",
      "Epoch =  76 Batch =  0 Loss =  50.71191890602808 Gradient_max =  0.3802927579739379 learning rate ratio =  0.0008782683304685513\n",
      "Epoch =  77 Batch =  0 Loss =  50.521654417800356 Gradient_max =  0.37970625207264525 learning rate ratio =  0.001523688590152217\n",
      "Epoch =  78 Batch =  0 Loss =  50.33252150218794 Gradient_max =  0.3791194207075878 learning rate ratio =  0.005771138956996107\n",
      "Epoch =  79 Batch =  0 Loss =  50.144483176035486 Gradient_max =  0.37853220115508884 learning rate ratio =  0.0003301273209825466\n",
      "Epoch =  80 Batch =  0 Loss =  49.957506530383476 Gradient_max =  0.37794452516745525 learning rate ratio =  0.00038371210275573613\n",
      "Epoch =  81 Batch =  0 Loss =  49.7716119223927 Gradient_max =  0.3773564737278289 learning rate ratio =  0.00045819482944664736\n",
      "Epoch =  82 Batch =  0 Loss =  49.586766931743355 Gradient_max =  0.37676799096028624 learning rate ratio =  0.0005687628282721372\n",
      "Epoch =  83 Batch =  0 Loss =  49.402971639193616 Gradient_max =  0.3761791097957902 learning rate ratio =  0.0007500245565880364\n",
      "Epoch =  84 Batch =  0 Loss =  49.22020971374773 Gradient_max =  0.3755898378091933 learning rate ratio =  0.0011016412991931759\n",
      "Epoch =  85 Batch =  0 Loss =  49.03848128470853 Gradient_max =  0.37500021067706657 learning rate ratio =  0.002076677244417409\n",
      "Epoch =  86 Batch =  0 Loss =  48.857790505327664 Gradient_max =  0.3744102759234033 learning rate ratio =  0.018284305832055037\n",
      "Epoch =  87 Batch =  0 Loss =  48.67812631550657 Gradient_max =  0.3738200350721381 learning rate ratio =  5.912269618308622e-05\n",
      "Epoch =  88 Batch =  0 Loss =  48.4994750660911 Gradient_max =  0.37322948151275037 learning rate ratio =  6.0442504336900315e-05\n",
      "Epoch =  89 Batch =  0 Loss =  48.32184508788784 Gradient_max =  0.37263867702654846 learning rate ratio =  6.182237645471041e-05\n",
      "Epoch =  90 Batch =  0 Loss =  48.14523260213425 Gradient_max =  0.37204764527618167 learning rate ratio =  6.326971195998601e-05\n",
      "Epoch =  91 Batch =  0 Loss =  47.96969868873071 Gradient_max =  0.3714566494864485 learning rate ratio =  5.9882043151178845e-05\n",
      "Epoch =  92 Batch =  0 Loss =  47.795245986531285 Gradient_max =  0.37086568392436947 learning rate ratio =  6.134736181424639e-05\n",
      "Epoch =  93 Batch =  0 Loss =  47.62184061980575 Gradient_max =  0.37027473683054024 learning rate ratio =  6.287642722752782e-05\n",
      "Epoch =  94 Batch =  0 Loss =  47.44945683551024 Gradient_max =  0.3696837461501683 learning rate ratio =  6.448306146538644e-05\n",
      "Epoch =  95 Batch =  0 Loss =  47.27807282006451 Gradient_max =  0.36909265893386733 learning rate ratio =  6.61741349381792e-05\n",
      "Epoch =  96 Batch =  0 Loss =  47.10767964737161 Gradient_max =  0.36850148231515 learning rate ratio =  6.795915857022905e-05\n",
      "Epoch =  97 Batch =  0 Loss =  46.93827837264769 Gradient_max =  0.36791025733489036 learning rate ratio =  6.985015171177204e-05\n",
      "Epoch =  98 Batch =  0 Loss =  46.76991949766163 Gradient_max =  0.3673191910330346 learning rate ratio =  7.185135470335695e-05\n",
      "Epoch =  99 Batch =  0 Loss =  46.602569187139835 Gradient_max =  0.3667282243264033 learning rate ratio =  7.396922875191676e-05\n",
      "Epoch =  100 Batch =  0 Loss =  46.436201612848215 Gradient_max =  0.36613728637782206 learning rate ratio =  7.621638569525899e-05\n",
      "Epoch =  101 Batch =  0 Loss =  46.270821070903644 Gradient_max =  0.3655464334756863 learning rate ratio =  7.861119705555194e-05\n",
      "Epoch =  102 Batch =  0 Loss =  46.106453117664984 Gradient_max =  0.3649557906976911 learning rate ratio =  8.116289303615457e-05\n",
      "Epoch =  103 Batch =  0 Loss =  45.943059679917866 Gradient_max =  0.36436525940128955 learning rate ratio =  8.388670300234274e-05\n",
      "Epoch =  104 Batch =  0 Loss =  45.78063734330475 Gradient_max =  0.36377486244597945 learning rate ratio =  8.679775469743267e-05\n",
      "Epoch =  105 Batch =  0 Loss =  45.619185961417706 Gradient_max =  0.3631846309414074 learning rate ratio =  8.992172707145818e-05\n",
      "Epoch =  106 Batch =  0 Loss =  45.45870600235824 Gradient_max =  0.3625946121739823 learning rate ratio =  9.32637628808201e-05\n",
      "Epoch =  107 Batch =  0 Loss =  45.299215509648896 Gradient_max =  0.3620049035971166 learning rate ratio =  9.686555420774742e-05\n",
      "Epoch =  108 Batch =  0 Loss =  45.140684140382454 Gradient_max =  0.36141543635365286 learning rate ratio =  0.00010074920370598595\n",
      "Epoch =  109 Batch =  0 Loss =  44.98310654155961 Gradient_max =  0.3608262280532886 learning rate ratio =  0.00010496395486947597\n",
      "Epoch =  110 Batch =  0 Loss =  44.8264834821272 Gradient_max =  0.36023731881916576 learning rate ratio =  0.00010952734048457408\n",
      "Epoch =  111 Batch =  0 Loss =  44.670804276710875 Gradient_max =  0.359648707140516 learning rate ratio =  0.0001145057430076164\n",
      "Epoch =  112 Batch =  0 Loss =  44.51606402216847 Gradient_max =  0.3590604130457704 learning rate ratio =  0.00011995407613986364\n",
      "Epoch =  113 Batch =  0 Loss =  44.362261379439154 Gradient_max =  0.3584724681725623 learning rate ratio =  0.00012594202099111502\n",
      "Epoch =  114 Batch =  0 Loss =  44.2093929123638 Gradient_max =  0.35788489614820407 learning rate ratio =  0.00013255859488867715\n",
      "Epoch =  115 Batch =  0 Loss =  44.05747335783493 Gradient_max =  0.35729779510916776 learning rate ratio =  0.00013328657904459486\n",
      "Epoch =  116 Batch =  0 Loss =  43.906505723229905 Gradient_max =  0.35671121493312635 learning rate ratio =  0.0001410702187369581\n",
      "Epoch =  117 Batch =  0 Loss =  43.756459125187966 Gradient_max =  0.35612507007826893 learning rate ratio =  0.0001498140560305584\n",
      "Epoch =  118 Batch =  0 Loss =  43.607344734338696 Gradient_max =  0.35553942532154764 learning rate ratio =  0.00015967657699675778\n",
      "Epoch =  119 Batch =  0 Loss =  43.45916624802007 Gradient_max =  0.35495435635107975 learning rate ratio =  0.00017088169343726698\n",
      "Epoch =  120 Batch =  0 Loss =  43.31189886320044 Gradient_max =  0.35436980315437155 learning rate ratio =  0.00018380898088373062\n",
      "Epoch =  121 Batch =  0 Loss =  43.165572039286005 Gradient_max =  0.3537859369108536 learning rate ratio =  0.00019887277417571112\n",
      "Epoch =  122 Batch =  0 Loss =  43.02016998837413 Gradient_max =  0.35320272509287304 learning rate ratio =  0.00021660150502724\n",
      "Epoch =  123 Batch =  0 Loss =  42.87566321901408 Gradient_max =  0.35262007367876125 learning rate ratio =  0.00023785586552681673\n",
      "Epoch =  124 Batch =  0 Loss =  42.73205497613802 Gradient_max =  0.35203802660033184 learning rate ratio =  0.00026375086491701495\n",
      "Epoch =  125 Batch =  0 Loss =  42.589340881636225 Gradient_max =  0.3514566092052679 learning rate ratio =  0.0002959711141012604\n",
      "Epoch =  126 Batch =  0 Loss =  42.44751866437799 Gradient_max =  0.35087585153643014 learning rate ratio =  0.00033717948671824915\n",
      "Epoch =  127 Batch =  0 Loss =  42.30658748752169 Gradient_max =  0.35029577209360147 learning rate ratio =  0.0003916845741141356\n",
      "Epoch =  128 Batch =  0 Loss =  42.16654795860375 Gradient_max =  0.3497164023617611 learning rate ratio =  0.0004672236445795402\n",
      "Epoch =  129 Batch =  0 Loss =  42.02738638325072 Gradient_max =  0.34913773713186297 learning rate ratio =  0.0005788900398727572\n",
      "Epoch =  130 Batch =  0 Loss =  41.889125453779336 Gradient_max =  0.3485598823179527 learning rate ratio =  0.0007348564467585137\n",
      "Epoch =  131 Batch =  0 Loss =  41.75175014938807 Gradient_max =  0.34798282988225854 learning rate ratio =  0.0010691561765546781\n",
      "Epoch =  132 Batch =  0 Loss =  41.61525448631062 Gradient_max =  0.34740659601474755 learning rate ratio =  0.0019666491413176165\n",
      "Epoch =  133 Batch =  0 Loss =  41.47961606691939 Gradient_max =  0.34683113448911407 learning rate ratio =  0.012400218168594572\n",
      "Epoch =  134 Batch =  0 Loss =  41.34483232990348 Gradient_max =  0.34625647062339887 learning rate ratio =  0.00028279150695472235\n",
      "Epoch =  135 Batch =  0 Loss =  41.210900195172634 Gradient_max =  0.34568262434342095 learning rate ratio =  0.00032256542006723515\n",
      "Epoch =  136 Batch =  0 Loss =  41.077821116727314 Gradient_max =  0.34510964195609317 learning rate ratio =  0.00037545742178260265\n",
      "Epoch =  137 Batch =  0 Loss =  40.94559257865911 Gradient_max =  0.3445375516031976 learning rate ratio =  0.000449238900546461\n",
      "Epoch =  138 Batch =  0 Loss =  40.81420126661089 Gradient_max =  0.3439663277642825 learning rate ratio =  0.0005593301222371652\n",
      "Epoch =  139 Batch =  0 Loss =  40.683644691095154 Gradient_max =  0.34339599516967345 learning rate ratio =  0.0007412822507774075\n",
      "Epoch =  140 Batch =  0 Loss =  40.55391743725087 Gradient_max =  0.3428265660388584 learning rate ratio =  0.0010995434378919513\n",
      "Epoch =  141 Batch =  0 Loss =  40.42504658228421 Gradient_max =  0.34225815588703307 learning rate ratio =  0.0021312184429573048\n",
      "Epoch =  142 Batch =  0 Loss =  40.29700667626168 Gradient_max =  0.3416907125440955 learning rate ratio =  0.03539415242107031\n",
      "Epoch =  143 Batch =  0 Loss =  40.16978391896608 Gradient_max =  0.34112422540654525 learning rate ratio =  0.0001327666757145181\n",
      "Epoch =  144 Batch =  0 Loss =  40.04338711131594 Gradient_max =  0.3405587808532131 learning rate ratio =  0.00014146853677998592\n",
      "Epoch =  145 Batch =  0 Loss =  39.91780003225953 Gradient_max =  0.33999433068337437 learning rate ratio =  0.00015140844068874552\n",
      "Epoch =  146 Batch =  0 Loss =  39.79302104739008 Gradient_max =  0.33943090021299555 learning rate ratio =  0.0001628708262655798\n",
      "Epoch =  147 Batch =  0 Loss =  39.669045354883906 Gradient_max =  0.33886850334285284 learning rate ratio =  0.00017623448140966985\n",
      "Epoch =  148 Batch =  0 Loss =  39.54586674062037 Gradient_max =  0.33830714776375487 learning rate ratio =  0.00019201520586097431\n",
      "Epoch =  149 Batch =  0 Loss =  39.4234801307341 Gradient_max =  0.33774684464333027 learning rate ratio =  0.00021093392607383226\n",
      "Epoch =  150 Batch =  0 Loss =  39.30188302553804 Gradient_max =  0.33718761608490805 learning rate ratio =  0.0002340299275626754\n",
      "Epoch =  151 Batch =  0 Loss =  39.181084002405605 Gradient_max =  0.3366295350024835 learning rate ratio =  0.000262858409678469\n",
      "Epoch =  152 Batch =  0 Loss =  39.06106829483286 Gradient_max =  0.3360725692231717 learning rate ratio =  0.0002998558535387127\n",
      "Epoch =  153 Batch =  0 Loss =  38.941829082346445 Gradient_max =  0.33551671962377233 learning rate ratio =  0.0003490674683921041\n",
      "Epoch =  154 Batch =  0 Loss =  38.82336136138582 Gradient_max =  0.3349619984748224 learning rate ratio =  0.0004177373718877172\n",
      "Epoch =  155 Batch =  0 Loss =  38.7056649297504 Gradient_max =  0.33440843688004634 learning rate ratio =  0.0005202498512841407\n",
      "Epoch =  156 Batch =  0 Loss =  38.58873493292573 Gradient_max =  0.3338560441783382 learning rate ratio =  0.0006898028976822908\n",
      "Epoch =  157 Batch =  0 Loss =  38.472565239097634 Gradient_max =  0.3333048274347985 learning rate ratio =  0.0010241113935894055\n",
      "Epoch =  158 Batch =  0 Loss =  38.35715300123485 Gradient_max =  0.3327548050074064 learning rate ratio =  0.0019902351297488067\n",
      "Epoch =  159 Batch =  0 Loss =  38.24249625893911 Gradient_max =  0.33220599944655715 learning rate ratio =  0.03612752128967703\n",
      "Epoch =  160 Batch =  0 Loss =  38.12860902816071 Gradient_max =  0.3316585013024768 learning rate ratio =  0.00018962997588258025\n",
      "Epoch =  161 Batch =  0 Loss =  38.015465681929335 Gradient_max =  0.33111223311913646 learning rate ratio =  0.00020491486720530753\n",
      "Epoch =  162 Batch =  0 Loss =  37.90308472839152 Gradient_max =  0.33056729292531245 learning rate ratio =  0.00022291008109595622\n",
      "Epoch =  163 Batch =  0 Loss =  37.79147042088965 Gradient_max =  0.3300237169832298 learning rate ratio =  0.0002444064985236743\n",
      "Epoch =  164 Batch =  0 Loss =  37.68060723493675 Gradient_max =  0.3294814540555644 learning rate ratio =  0.00027053583643869096\n",
      "Epoch =  165 Batch =  0 Loss =  37.570482034811576 Gradient_max =  0.32894049448877005 learning rate ratio =  0.00030297647445772636\n",
      "Epoch =  166 Batch =  0 Loss =  37.461092359156794 Gradient_max =  0.328400857393108 learning rate ratio =  0.000344328869399438\n",
      "Epoch =  167 Batch =  0 Loss =  37.35242336251423 Gradient_max =  0.32786253413922506 learning rate ratio =  0.0003988494840362287\n",
      "Epoch =  168 Batch =  0 Loss =  37.2444682365452 Gradient_max =  0.32732552396542164 learning rate ratio =  0.00047401874929336974\n",
      "Epoch =  169 Batch =  0 Loss =  37.137223891194964 Gradient_max =  0.32678984241057607 learning rate ratio =  0.0005843064660658869\n",
      "Epoch =  170 Batch =  0 Loss =  37.03068607360315 Gradient_max =  0.3262554987048918 learning rate ratio =  0.0007618228473965987\n",
      "Epoch =  171 Batch =  0 Loss =  36.92484988651115 Gradient_max =  0.3257224998736321 learning rate ratio =  0.001094985686526335\n",
      "Epoch =  172 Batch =  0 Loss =  36.819711134515835 Gradient_max =  0.3251908556886074 learning rate ratio =  0.001948290396854099\n",
      "Epoch =  173 Batch =  0 Loss =  36.715265638043995 Gradient_max =  0.32466057547062377 learning rate ratio =  0.008873724337363074\n",
      "Epoch =  174 Batch =  0 Loss =  36.61151037284784 Gradient_max =  0.32413167408099275 learning rate ratio =  6.214858189802178e-05\n",
      "Epoch =  175 Batch =  0 Loss =  36.50844191665032 Gradient_max =  0.32360416394461305 learning rate ratio =  6.256604412191714e-05\n",
      "Epoch =  176 Batch =  0 Loss =  36.40605764497107 Gradient_max =  0.32307806155376834 learning rate ratio =  6.298161890175241e-05\n",
      "Epoch =  177 Batch =  0 Loss =  36.30435302633706 Gradient_max =  0.32255337422741165 learning rate ratio =  6.340349848353859e-05\n",
      "Epoch =  178 Batch =  0 Loss =  36.203321638949994 Gradient_max =  0.32203010010698596 learning rate ratio =  6.383268003787419e-05\n",
      "Epoch =  179 Batch =  0 Loss =  36.10296189400814 Gradient_max =  0.32150825994677157 learning rate ratio =  6.42620793238645e-05\n",
      "Epoch =  180 Batch =  0 Loss =  36.00326917033504 Gradient_max =  0.32098785894462994 learning rate ratio =  6.469065370828484e-05\n",
      "Epoch =  181 Batch =  0 Loss =  35.90423862658991 Gradient_max =  0.3204689015680988 learning rate ratio =  6.512656068229066e-05\n",
      "Epoch =  182 Batch =  0 Loss =  35.80587282762 Gradient_max =  0.31995143650295566 learning rate ratio =  6.556900906526809e-05\n",
      "Epoch =  183 Batch =  0 Loss =  35.70816848404914 Gradient_max =  0.31943547512414 learning rate ratio =  6.601509921329342e-05\n",
      "Epoch =  184 Batch =  0 Loss =  35.61111694832938 Gradient_max =  0.31892099811526337 learning rate ratio =  6.646897995704567e-05\n",
      "Epoch =  185 Batch =  0 Loss =  35.514719778655575 Gradient_max =  0.31840804473014606 learning rate ratio =  6.361243224319169e-05\n",
      "Epoch =  186 Batch =  0 Loss =  35.41896571573579 Gradient_max =  0.3178965780722316 learning rate ratio =  6.405577055569909e-05\n",
      "Epoch =  187 Batch =  0 Loss =  35.32385074580064 Gradient_max =  0.31738660607538693 learning rate ratio =  6.450706381060758e-05\n",
      "Epoch =  188 Batch =  0 Loss =  35.2293764664085 Gradient_max =  0.3168781648839594 learning rate ratio =  6.496485166328498e-05\n",
      "Epoch =  189 Batch =  0 Loss =  35.13554041511028 Gradient_max =  0.3163712685470723 learning rate ratio =  6.542945331868084e-05\n",
      "Epoch =  190 Batch =  0 Loss =  35.04233228618578 Gradient_max =  0.3158658899600522 learning rate ratio =  6.590136461678982e-05\n",
      "Epoch =  191 Batch =  0 Loss =  34.94974834926282 Gradient_max =  0.31536203605405716 learning rate ratio =  6.6381128965179e-05\n",
      "Epoch =  192 Batch =  0 Loss =  34.85778531567566 Gradient_max =  0.31485971695440934 learning rate ratio =  6.686996414039437e-05\n",
      "Epoch =  193 Batch =  0 Loss =  34.76643790530806 Gradient_max =  0.314358930004716 learning rate ratio =  6.73681500797436e-05\n",
      "Epoch =  194 Batch =  0 Loss =  34.67570269417913 Gradient_max =  0.31385968350854093 learning rate ratio =  6.858874582127086e-05\n",
      "Epoch =  195 Batch =  0 Loss =  34.58557539244762 Gradient_max =  0.31336198178256275 learning rate ratio =  7.077010865513903e-05\n",
      "Epoch =  196 Batch =  0 Loss =  34.496052833574595 Gradient_max =  0.31286583416553926 learning rate ratio =  7.309872850188127e-05\n",
      "Epoch =  197 Batch =  0 Loss =  34.407131969084375 Gradient_max =  0.31237124884535566 learning rate ratio =  7.559001651018699e-05\n",
      "Epoch =  198 Batch =  0 Loss =  34.31881150735202 Gradient_max =  0.3118782435641003 learning rate ratio =  7.826161244158202e-05\n",
      "Epoch =  199 Batch =  0 Loss =  34.231092119783256 Gradient_max =  0.3113868506359578 learning rate ratio =  8.113380735908655e-05\n",
      "Epoch =  200 Batch =  0 Loss =  34.14396299627681 Gradient_max =  0.31089703656971984 learning rate ratio =  8.423003846741655e-05\n",
      "Epoch =  201 Batch =  0 Loss =  34.05742994330095 Gradient_max =  0.31040886995163697 learning rate ratio =  8.757756626354357e-05\n",
      "Epoch =  202 Batch =  0 Loss =  33.97147966316912 Gradient_max =  0.3099222899882751 learning rate ratio =  9.120822768096699e-05\n",
      "Epoch =  203 Batch =  0 Loss =  33.88610806920061 Gradient_max =  0.30943729983450674 learning rate ratio =  9.515949346350091e-05\n",
      "Epoch =  204 Batch =  0 Loss =  33.801310754755086 Gradient_max =  0.30895389983929167 learning rate ratio =  9.947574981466467e-05\n",
      "Epoch =  205 Batch =  0 Loss =  33.71708531583325 Gradient_max =  0.30847209875876075 learning rate ratio =  0.00010420997575657751\n",
      "Epoch =  206 Batch =  0 Loss =  33.63342784590398 Gradient_max =  0.30799189982436115 learning rate ratio =  0.00010942592252753859\n",
      "Epoch =  207 Batch =  0 Loss =  33.55033612214105 Gradient_max =  0.30751331199932236 learning rate ratio =  0.0001152010023521183\n",
      "Epoch =  208 Batch =  0 Loss =  33.46781346839286 Gradient_max =  0.3070363688416196 learning rate ratio =  0.00012163016182918051\n",
      "Epoch =  209 Batch =  0 Loss =  33.38584753628798 Gradient_max =  0.3065610362493251 learning rate ratio =  0.0001288311038543287\n",
      "Epoch =  210 Batch =  0 Loss =  33.304434576504626 Gradient_max =  0.30608731773090747 learning rate ratio =  0.00013695159467120487\n",
      "Epoch =  211 Batch =  0 Loss =  33.22357101815994 Gradient_max =  0.3056152168857752 learning rate ratio =  0.00014617969367551015\n",
      "Epoch =  212 Batch =  0 Loss =  33.143253933893625 Gradient_max =  0.30514474028691824 learning rate ratio =  0.00015675849376104608\n",
      "Epoch =  213 Batch =  0 Loss =  33.063478907523624 Gradient_max =  0.30467588592519 learning rate ratio =  0.00016900783380680308\n",
      "Epoch =  214 Batch =  0 Loss =  32.984242625638096 Gradient_max =  0.3042086581178832 learning rate ratio =  0.0001833571925193591\n",
      "Epoch =  215 Batch =  0 Loss =  32.90554122501257 Gradient_max =  0.30374305705397636 learning rate ratio =  0.00020039706239514583\n",
      "Epoch =  216 Batch =  0 Loss =  32.82737189003753 Gradient_max =  0.3032790887809046 learning rate ratio =  0.00022096221940758463\n",
      "Epoch =  217 Batch =  0 Loss =  32.74973141623024 Gradient_max =  0.3028167563750981 learning rate ratio =  0.0002462726080445948\n",
      "Epoch =  218 Batch =  0 Loss =  32.67261580801395 Gradient_max =  0.30235605885997796 learning rate ratio =  0.0002781844557386747\n",
      "Epoch =  219 Batch =  0 Loss =  32.59602704743752 Gradient_max =  0.30189704004272055 learning rate ratio =  0.00031966735097871266\n",
      "Epoch =  220 Batch =  0 Loss =  32.51996635700647 Gradient_max =  0.3014397157627244 learning rate ratio =  0.0003757861254190089\n",
      "Epoch =  221 Batch =  0 Loss =  32.44442462285671 Gradient_max =  0.30098405211421575 learning rate ratio =  0.00045594451100680345\n",
      "Epoch =  222 Batch =  0 Loss =  32.36939464169111 Gradient_max =  0.3005300342548442 learning rate ratio =  0.0005797979359083461\n",
      "Epoch =  223 Batch =  0 Loss =  32.29487446510576 Gradient_max =  0.30007766798641494 learning rate ratio =  0.0007964576037591674\n",
      "Epoch =  224 Batch =  0 Loss =  32.220858610541406 Gradient_max =  0.2996269466932082 learning rate ratio =  0.0012727261831564196\n",
      "Epoch =  225 Batch =  0 Loss =  32.1473444635312 Gradient_max =  0.2991778740856223 learning rate ratio =  0.003172508262169284\n",
      "Epoch =  226 Batch =  0 Loss =  32.074328095920265 Gradient_max =  0.2987304498004607 learning rate ratio =  8.786175311311445e-05\n",
      "Epoch =  227 Batch =  0 Loss =  32.001806115612624 Gradient_max =  0.2982846747617417 learning rate ratio =  8.859762989588433e-05\n",
      "Epoch =  228 Batch =  0 Loss =  31.92977573706421 Gradient_max =  0.29784055215347627 learning rate ratio =  8.934958231511887e-05\n",
      "Epoch =  229 Batch =  0 Loss =  31.858235776695437 Gradient_max =  0.29739810055250576 learning rate ratio =  9.011815422723731e-05\n",
      "Epoch =  230 Batch =  0 Loss =  31.787181532553745 Gradient_max =  0.29695730704128287 learning rate ratio =  9.090390734972939e-05\n",
      "Epoch =  231 Batch =  0 Loss =  31.716608701040283 Gradient_max =  0.2965181644542193 learning rate ratio =  9.170742920794351e-05\n",
      "Epoch =  232 Batch =  0 Loss =  31.64651385745332 Gradient_max =  0.29608067193969356 learning rate ratio =  9.252933572978748e-05\n",
      "Epoch =  233 Batch =  0 Loss =  31.576894248153668 Gradient_max =  0.29564483265271013 learning rate ratio =  9.337027207606007e-05\n",
      "Epoch =  234 Batch =  0 Loss =  31.507747217374025 Gradient_max =  0.29521064856991563 learning rate ratio =  9.423090909076825e-05\n",
      "Epoch =  235 Batch =  0 Loss =  31.439068917602103 Gradient_max =  0.29477811597112996 learning rate ratio =  9.511195342288954e-05\n",
      "Epoch =  236 Batch =  0 Loss =  31.370856142756008 Gradient_max =  0.29434723511197064 learning rate ratio =  9.60073655289388e-05\n",
      "Epoch =  237 Batch =  0 Loss =  31.30310565728519 Gradient_max =  0.29391800438568044 learning rate ratio =  9.689521183314289e-05\n",
      "Epoch =  238 Batch =  0 Loss =  31.23581477278 Gradient_max =  0.2934904254047533 learning rate ratio =  9.780382473904737e-05\n",
      "Epoch =  239 Batch =  0 Loss =  31.168980200895003 Gradient_max =  0.29306449739828244 learning rate ratio =  9.872250650279542e-05\n",
      "Epoch =  240 Batch =  0 Loss =  31.102604753607547 Gradient_max =  0.2926402605556474 learning rate ratio =  9.965980671974235e-05\n",
      "Epoch =  241 Batch =  0 Loss =  31.03667995634112 Gradient_max =  0.2922176778976194 learning rate ratio =  0.00010061988535626547\n",
      "Epoch =  242 Batch =  0 Loss =  30.971201950745662 Gradient_max =  0.2917967427095146 learning rate ratio =  0.00010160363050701456\n",
      "Epoch =  243 Batch =  0 Loss =  30.906167969252 Gradient_max =  0.29137745529091624 learning rate ratio =  0.00010261193094054291\n",
      "Epoch =  244 Batch =  0 Loss =  30.84157746765001 Gradient_max =  0.2909598212575563 learning rate ratio =  0.00010364568195875047\n",
      "Epoch =  245 Batch =  0 Loss =  30.777427435476667 Gradient_max =  0.2905438390241812 learning rate ratio =  0.00010470586401841406\n",
      "Epoch =  246 Batch =  0 Loss =  30.71371239916109 Gradient_max =  0.29012950121968867 learning rate ratio =  0.0001057935502297399\n",
      "Epoch =  247 Batch =  0 Loss =  30.65042914791851 Gradient_max =  0.28971680517610165 learning rate ratio =  0.0001069098281331035\n",
      "Epoch =  248 Batch =  0 Loss =  30.58757461265792 Gradient_max =  0.2893057486906368 learning rate ratio =  0.00010805584116895683\n",
      "Epoch =  249 Batch =  0 Loss =  30.52514594246856 Gradient_max =  0.2888963307270338 learning rate ratio =  0.00010919392452464706\n",
      "Epoch =  250 Batch =  0 Loss =  30.463140418226093 Gradient_max =  0.28848855040735444 learning rate ratio =  0.00011035062380260569\n",
      "Epoch =  251 Batch =  0 Loss =  30.401559948172782 Gradient_max =  0.28808243450433085 learning rate ratio =  0.000111533490886968\n",
      "Epoch =  252 Batch =  0 Loss =  30.34040489803975 Gradient_max =  0.2876780044753925 learning rate ratio =  0.00011274826283656877\n",
      "Epoch =  253 Batch =  0 Loss =  30.279665651618245 Gradient_max =  0.2872752149366705 learning rate ratio =  0.00011396302568639799\n",
      "Epoch =  254 Batch =  0 Loss =  30.21933782257641 Gradient_max =  0.2868740550812197 learning rate ratio =  0.00011520716683291703\n",
      "Epoch =  255 Batch =  0 Loss =  30.159418888517905 Gradient_max =  0.28647452408826357 learning rate ratio =  0.000116466485358205\n",
      "Epoch =  256 Batch =  0 Loss =  30.09990589376527 Gradient_max =  0.2860766191099493 learning rate ratio =  0.00011775708205983042\n",
      "Epoch =  257 Batch =  0 Loss =  30.040796076199594 Gradient_max =  0.28568033824581895 learning rate ratio =  0.00011907009375607956\n",
      "Epoch =  258 Batch =  0 Loss =  29.982086402232618 Gradient_max =  0.28528567800844096 learning rate ratio =  0.00012041920814434197\n",
      "Epoch =  259 Batch =  0 Loss =  29.923774415524168 Gradient_max =  0.28489263796792696 learning rate ratio =  0.00012180662489929521\n",
      "Epoch =  260 Batch =  0 Loss =  29.865857160606605 Gradient_max =  0.28450121403486267 learning rate ratio =  0.00012323400348472448\n",
      "Epoch =  261 Batch =  0 Loss =  29.80833182126335 Gradient_max =  0.2841114034893235 learning rate ratio =  0.00012470309408308755\n",
      "Epoch =  262 Batch =  0 Loss =  29.751195567840423 Gradient_max =  0.2837232029098195 learning rate ratio =  0.00012621574858905972\n",
      "Epoch =  263 Batch =  0 Loss =  29.69444670981691 Gradient_max =  0.2833366159313706 learning rate ratio =  0.000127773929209678\n",
      "Epoch =  264 Batch =  0 Loss =  29.638083032587907 Gradient_max =  0.28295164292682273 learning rate ratio =  0.00012936424526479128\n",
      "Epoch =  265 Batch =  0 Loss =  29.582100657700757 Gradient_max =  0.2825682729894527 learning rate ratio =  0.00013100286781983036\n",
      "Epoch =  266 Batch =  0 Loss =  29.526497978768017 Gradient_max =  0.2821865096732824 learning rate ratio =  0.00013269266610367592\n",
      "Epoch =  267 Batch =  0 Loss =  29.47127216810528 Gradient_max =  0.28180634880162425 learning rate ratio =  0.00013443607680811576\n",
      "Epoch =  268 Batch =  0 Loss =  29.416420055201346 Gradient_max =  0.28142778406221813 learning rate ratio =  0.0001362356844875543\n",
      "Epoch =  269 Batch =  0 Loss =  29.361938885870845 Gradient_max =  0.28105081117664676 learning rate ratio =  0.0001380842519381497\n",
      "Epoch =  270 Batch =  0 Loss =  29.30782618089635 Gradient_max =  0.2806754272234453 learning rate ratio =  0.00013998252713730137\n",
      "Epoch =  271 Batch =  0 Loss =  29.254079360294625 Gradient_max =  0.2803016290884807 learning rate ratio =  0.00014194428933523312\n",
      "Epoch =  272 Batch =  0 Loss =  29.20070220892644 Gradient_max =  0.27992946304240557 learning rate ratio =  0.0001439729148930527\n",
      "Epoch =  273 Batch =  0 Loss =  29.14768792489342 Gradient_max =  0.2795588902716307 learning rate ratio =  0.00014607187178529866\n",
      "Epoch =  274 Batch =  0 Loss =  29.09503169314565 Gradient_max =  0.27918989191176585 learning rate ratio =  0.00014824487111795532\n",
      "Epoch =  275 Batch =  0 Loss =  29.04273095013136 Gradient_max =  0.27882246405389455 learning rate ratio =  0.00015035187439920122\n",
      "Epoch =  276 Batch =  0 Loss =  28.990783178977882 Gradient_max =  0.27845660309473524 learning rate ratio =  0.0001524943997587951\n",
      "Epoch =  277 Batch =  0 Loss =  28.939186280298983 Gradient_max =  0.27809230731177687 learning rate ratio =  0.00015471059589123738\n",
      "Epoch =  278 Batch =  0 Loss =  28.88793751533998 Gradient_max =  0.2777295717658242 learning rate ratio =  0.0001570047922161565\n",
      "Epoch =  279 Batch =  0 Loss =  28.837034772683552 Gradient_max =  0.2773683943516747 learning rate ratio =  0.00015938116970733217\n",
      "Epoch =  280 Batch =  0 Loss =  28.786475484604733 Gradient_max =  0.27700877073391134 learning rate ratio =  0.00016184421040025605\n",
      "Epoch =  281 Batch =  0 Loss =  28.736259653278427 Gradient_max =  0.2766507121472198 learning rate ratio =  0.0001529287616399308\n",
      "Epoch =  282 Batch =  0 Loss =  28.686383934903375 Gradient_max =  0.27629420916894676 learning rate ratio =  0.00015537262930724724\n",
      "Epoch =  283 Batch =  0 Loss =  28.63684438546606 Gradient_max =  0.2759392477935071 learning rate ratio =  0.00015790053821081198\n",
      "Epoch =  284 Batch =  0 Loss =  28.587638578988987 Gradient_max =  0.27558582369437457 learning rate ratio =  0.00016052465567873483\n",
      "Epoch =  285 Batch =  0 Loss =  28.538764236722944 Gradient_max =  0.2752339332324732 learning rate ratio =  0.0001632528247643164\n",
      "Epoch =  286 Batch =  0 Loss =  28.49021914483359 Gradient_max =  0.2748835728819727 learning rate ratio =  0.0001660913632370023\n",
      "Epoch =  287 Batch =  0 Loss =  28.442000985119012 Gradient_max =  0.2745347385457033 learning rate ratio =  0.00016904708224523368\n",
      "Epoch =  288 Batch =  0 Loss =  28.39410761882019 Gradient_max =  0.27418742704584315 learning rate ratio =  0.0001721273634491364\n",
      "Epoch =  289 Batch =  0 Loss =  28.346536728141707 Gradient_max =  0.27384163434884257 learning rate ratio =  0.00017534022445932188\n",
      "Epoch =  290 Batch =  0 Loss =  28.299286197602598 Gradient_max =  0.27349735691605226 learning rate ratio =  0.00017866333761545818\n",
      "Epoch =  291 Batch =  0 Loss =  28.252353831093068 Gradient_max =  0.27315459078714194 learning rate ratio =  0.00018213358712936855\n",
      "Epoch =  292 Batch =  0 Loss =  28.20573721517645 Gradient_max =  0.2728133305529829 learning rate ratio =  0.00018576199401630015\n",
      "Epoch =  293 Batch =  0 Loss =  28.15943412923117 Gradient_max =  0.27247357200575745 learning rate ratio =  0.00018955960014796255\n",
      "Epoch =  294 Batch =  0 Loss =  28.113442375238893 Gradient_max =  0.2721353109894218 learning rate ratio =  0.00019353848564747562\n",
      "Epoch =  295 Batch =  0 Loss =  28.067759806692504 Gradient_max =  0.27179854344591114 learning rate ratio =  0.00019771190665085077\n",
      "Epoch =  296 Batch =  0 Loss =  28.02238427874417 Gradient_max =  0.2714632649410311 learning rate ratio =  0.0002020944423901531\n",
      "Epoch =  297 Batch =  0 Loss =  27.97731353898649 Gradient_max =  0.27112947052778746 learning rate ratio =  0.00020667264803758722\n",
      "Epoch =  298 Batch =  0 Loss =  27.932545542855735 Gradient_max =  0.27079715633907664 learning rate ratio =  0.00021144721074790884\n",
      "Epoch =  299 Batch =  0 Loss =  27.88807813283203 Gradient_max =  0.2704663178084355 learning rate ratio =  0.00021647598737005604\n",
      "Epoch =  300 Batch =  0 Loss =  27.84390928583004 Gradient_max =  0.27013695111625535 learning rate ratio =  0.0002217804145674048\n",
      "Epoch =  301 Batch =  0 Loss =  27.800036882532588 Gradient_max =  0.269809051299082 learning rate ratio =  0.00022738374060845003\n",
      "Epoch =  302 Batch =  0 Loss =  27.756458873439446 Gradient_max =  0.2694826139381409 learning rate ratio =  0.0002332223690208195\n",
      "Epoch =  303 Batch =  0 Loss =  27.71317309063054 Gradient_max =  0.26915763397087195 learning rate ratio =  0.00023939540282123196\n",
      "Epoch =  304 Batch =  0 Loss =  27.67017757349067 Gradient_max =  0.26883410723174533 learning rate ratio =  0.0002458287235220126\n",
      "Epoch =  305 Batch =  0 Loss =  27.62747041249759 Gradient_max =  0.2685120297221337 learning rate ratio =  0.0002524713389907664\n",
      "Epoch =  306 Batch =  0 Loss =  27.585049555133484 Gradient_max =  0.2681913967656768 learning rate ratio =  0.00025949565630975025\n",
      "Epoch =  307 Batch =  0 Loss =  27.54291292928737 Gradient_max =  0.26787220338692835 learning rate ratio =  0.0002669060129738378\n",
      "Epoch =  308 Batch =  0 Loss =  27.501058446318 Gradient_max =  0.26755444433782233 learning rate ratio =  0.00027475103726117456\n",
      "Epoch =  309 Batch =  0 Loss =  27.45948416824982 Gradient_max =  0.2672381151866736 learning rate ratio =  0.00028311949746615635\n",
      "Epoch =  310 Batch =  0 Loss =  27.418188416561755 Gradient_max =  0.26692321247686 learning rate ratio =  0.0002920661134145498\n",
      "Epoch =  311 Batch =  0 Loss =  27.377170160652714 Gradient_max =  0.2666097340676938 learning rate ratio =  0.0003016528098917533\n",
      "Epoch =  312 Batch =  0 Loss =  27.336426253970664 Gradient_max =  0.2662976712049726 learning rate ratio =  0.0003119507295743442\n",
      "Epoch =  313 Batch =  0 Loss =  27.295954723251068 Gradient_max =  0.26598701892762755 learning rate ratio =  0.0003230419296540404\n",
      "Epoch =  314 Batch =  0 Loss =  27.25575370408927 Gradient_max =  0.2656777726813928 learning rate ratio =  0.0003349117425326749\n",
      "Epoch =  315 Batch =  0 Loss =  27.2158213731201 Gradient_max =  0.2653699279544826 learning rate ratio =  0.00034756077568853365\n",
      "Epoch =  316 Batch =  0 Loss =  27.176155873159836 Gradient_max =  0.26506348006964986 learning rate ratio =  0.00036125851099018304\n",
      "Epoch =  317 Batch =  0 Loss =  27.13675533066858 Gradient_max =  0.26475842421092816 learning rate ratio =  0.0003760335041342357\n",
      "Epoch =  318 Batch =  0 Loss =  27.097618352368297 Gradient_max =  0.26445475801188684 learning rate ratio =  0.00039199934706957265\n",
      "Epoch =  319 Batch =  0 Loss =  27.05874499935754 Gradient_max =  0.2641524910043065 learning rate ratio =  0.00040943094885497665\n",
      "Epoch =  320 Batch =  0 Loss =  27.020131004272223 Gradient_max =  0.263851601073866 learning rate ratio =  0.0004285940528075117\n",
      "Epoch =  321 Batch =  0 Loss =  26.981774672581526 Gradient_max =  0.263552083708547 learning rate ratio =  0.00044976594476629875\n",
      "Epoch =  322 Batch =  0 Loss =  26.94367412871365 Gradient_max =  0.2632539338028996 learning rate ratio =  0.00047327971379817547\n",
      "Epoch =  323 Batch =  0 Loss =  26.90582752007347 Gradient_max =  0.26295714598862985 learning rate ratio =  0.0004995462996971606\n",
      "Epoch =  324 Batch =  0 Loss =  26.868233108506452 Gradient_max =  0.2626617156802417 learning rate ratio =  0.0005290787572873754\n",
      "Epoch =  325 Batch =  0 Loss =  26.830889079901766 Gradient_max =  0.26236763745188824 learning rate ratio =  0.0005624343713925626\n",
      "Epoch =  326 Batch =  0 Loss =  26.79379365748592 Gradient_max =  0.26207490617040735 learning rate ratio =  0.0006001569945146177\n",
      "Epoch =  327 Batch =  0 Loss =  26.756945119218717 Gradient_max =  0.26178351702299213 learning rate ratio =  0.0006434897171142155\n",
      "Epoch =  328 Batch =  0 Loss =  26.720341714874216 Gradient_max =  0.2614934648467788 learning rate ratio =  0.0006938773754526708\n",
      "Epoch =  329 Batch =  0 Loss =  26.683981745961585 Gradient_max =  0.2612047447459504 learning rate ratio =  0.0007531959857537836\n",
      "Epoch =  330 Batch =  0 Loss =  26.64786351304358 Gradient_max =  0.26091735170030805 learning rate ratio =  0.0008240498143952062\n",
      "Epoch =  331 Batch =  0 Loss =  26.611985355242354 Gradient_max =  0.2606312807443264 learning rate ratio =  0.0009101646467848711\n",
      "Epoch =  332 Batch =  0 Loss =  26.576345574062994 Gradient_max =  0.26034652677353964 learning rate ratio =  0.0010165258472181794\n",
      "Epoch =  333 Batch =  0 Loss =  26.540942550108298 Gradient_max =  0.2600630850389819 learning rate ratio =  0.0011500724756385902\n",
      "Epoch =  334 Batch =  0 Loss =  26.505774677454234 Gradient_max =  0.2597809508064466 learning rate ratio =  0.0013251464657253599\n",
      "Epoch =  335 Batch =  0 Loss =  26.470840283283433 Gradient_max =  0.25950011891270125 learning rate ratio =  0.0015647206779822306\n",
      "Epoch =  336 Batch =  0 Loss =  26.436137662657988 Gradient_max =  0.2592205837776868 learning rate ratio =  0.0019124827428963055\n",
      "Epoch =  337 Batch =  0 Loss =  26.401666321667484 Gradient_max =  0.2589423463945422 learning rate ratio =  0.0024630787807988198\n",
      "Epoch =  338 Batch =  0 Loss =  26.367423841364392 Gradient_max =  0.25866539727727333 learning rate ratio =  0.003423453131597167\n",
      "Epoch =  339 Batch =  0 Loss =  26.333408313904894 Gradient_max =  0.2583897297739518 learning rate ratio =  0.005621004796171623\n",
      "Epoch =  340 Batch =  0 Loss =  26.299618238193403 Gradient_max =  0.2581153392179054 learning rate ratio =  0.015860944388547387\n",
      "Epoch =  341 Batch =  0 Loss =  26.266051985169813 Gradient_max =  0.25784222024329906 learning rate ratio =  3.1232299568280423e-06\n",
      "Epoch =  342 Batch =  0 Loss =  26.232708013453028 Gradient_max =  0.25757036777014103 learning rate ratio =  3.110529529264249e-06\n",
      "Epoch =  343 Batch =  0 Loss =  26.199584740257773 Gradient_max =  0.25729977652378266 learning rate ratio =  3.0978638626076547e-06\n",
      "Epoch =  344 Batch =  0 Loss =  26.16668059673037 Gradient_max =  0.2570304413380341 learning rate ratio =  3.085233115261241e-06\n",
      "Epoch =  345 Batch =  0 Loss =  26.133994065297017 Gradient_max =  0.2567623571967425 learning rate ratio =  3.07262934541569e-06\n",
      "Epoch =  346 Batch =  0 Loss =  26.101523686090804 Gradient_max =  0.2564955193523318 learning rate ratio =  3.0600451102593508e-06\n",
      "Epoch =  347 Batch =  0 Loss =  26.069267929280795 Gradient_max =  0.256229922595668 learning rate ratio =  3.047492772299051e-06\n",
      "Epoch =  348 Batch =  0 Loss =  26.037225253947714 Gradient_max =  0.25596556148827004 learning rate ratio =  3.0349762520515144e-06\n",
      "Epoch =  349 Batch =  0 Loss =  26.00539418225695 Gradient_max =  0.25570243097741996 learning rate ratio =  3.0224905221314138e-06\n",
      "Epoch =  350 Batch =  0 Loss =  25.973773401413048 Gradient_max =  0.2554405270652228 learning rate ratio =  3.00997477948641e-06\n",
      "Epoch =  351 Batch =  0 Loss =  25.942361304896117 Gradient_max =  0.25517984364238355 learning rate ratio =  2.997494018334374e-06\n",
      "Epoch =  352 Batch =  0 Loss =  25.911156510024036 Gradient_max =  0.25492037613476537 learning rate ratio =  2.985011609881358e-06\n",
      "Epoch =  353 Batch =  0 Loss =  25.880158474064118 Gradient_max =  0.254662122594983 learning rate ratio =  2.972563959877819e-06\n",
      "Epoch =  354 Batch =  0 Loss =  25.849365030961604 Gradient_max =  0.254405075189534 learning rate ratio =  2.960154344421368e-06\n",
      "Epoch =  355 Batch =  0 Loss =  25.818774588020688 Gradient_max =  0.25414922828149683 learning rate ratio =  2.9477726537135424e-06\n",
      "Epoch =  356 Batch =  0 Loss =  25.78838569907327 Gradient_max =  0.25389457651148584 learning rate ratio =  2.935429094950256e-06\n",
      "Epoch =  357 Batch =  0 Loss =  25.758196942835937 Gradient_max =  0.25364111478675294 learning rate ratio =  2.9231122972020233e-06\n",
      "Epoch =  358 Batch =  0 Loss =  25.72820692503561 Gradient_max =  0.2533888379636423 learning rate ratio =  2.9108326908082765e-06\n",
      "Epoch =  359 Batch =  0 Loss =  25.698414230748835 Gradient_max =  0.25313774078158346 learning rate ratio =  2.8985919424919502e-06\n",
      "Epoch =  360 Batch =  0 Loss =  25.668817497158592 Gradient_max =  0.252887818222817 learning rate ratio =  2.8863901621800027e-06\n",
      "Epoch =  361 Batch =  0 Loss =  25.639415358468117 Gradient_max =  0.2526390651716037 learning rate ratio =  2.874227439336715e-06\n",
      "Epoch =  362 Batch =  0 Loss =  25.61020650011746 Gradient_max =  0.2523914768321399 learning rate ratio =  2.8621007419627674e-06\n",
      "Epoch =  363 Batch =  0 Loss =  25.581189550389134 Gradient_max =  0.2521450479023609 learning rate ratio =  2.850013211916919e-06\n",
      "Epoch =  364 Batch =  0 Loss =  25.55236321971448 Gradient_max =  0.25189977347526044 learning rate ratio =  2.837965023292749e-06\n",
      "Epoch =  365 Batch =  0 Loss =  25.523726171620797 Gradient_max =  0.2516556484772303 learning rate ratio =  2.825956253616754e-06\n",
      "Epoch =  366 Batch =  0 Loss =  25.495277089780636 Gradient_max =  0.2514126678943206 learning rate ratio =  2.8139751968030426e-06\n",
      "Epoch =  367 Batch =  0 Loss =  25.46701469176788 Gradient_max =  0.25117082669324864 learning rate ratio =  2.8020331546032677e-06\n",
      "Epoch =  368 Batch =  0 Loss =  25.438937703216318 Gradient_max =  0.2509301200155624 learning rate ratio =  2.7901153813478455e-06\n",
      "Epoch =  369 Batch =  0 Loss =  25.411044819330616 Gradient_max =  0.2506905427656044 learning rate ratio =  2.7782271617355483e-06\n",
      "Epoch =  370 Batch =  0 Loss =  25.383334757475634 Gradient_max =  0.2504520898034233 learning rate ratio =  2.766378718589743e-06\n",
      "Epoch =  371 Batch =  0 Loss =  25.35580624974776 Gradient_max =  0.2502147561225291 learning rate ratio =  2.7545653701131397e-06\n",
      "Epoch =  372 Batch =  0 Loss =  25.328458085261403 Gradient_max =  0.24997853698083883 learning rate ratio =  2.7427788160649387e-06\n",
      "Epoch =  373 Batch =  0 Loss =  25.30128898969986 Gradient_max =  0.24974342722223544 learning rate ratio =  2.7310311781455313e-06\n",
      "Epoch =  374 Batch =  0 Loss =  25.27429775584355 Gradient_max =  0.24950942194116238 learning rate ratio =  2.7193242378059354e-06\n",
      "Epoch =  375 Batch =  0 Loss =  25.247483115780877 Gradient_max =  0.24927651604221068 learning rate ratio =  2.7076475036553652e-06\n",
      "Epoch =  376 Batch =  0 Loss =  25.22084387152582 Gradient_max =  0.24904470466120388 learning rate ratio =  2.696007490647047e-06\n",
      "Epoch =  377 Batch =  0 Loss =  25.194378813912845 Gradient_max =  0.2488139828006047 learning rate ratio =  2.6844080790961694e-06\n",
      "Epoch =  378 Batch =  0 Loss =  25.16808673399919 Gradient_max =  0.24858434545925828 learning rate ratio =  2.672849733337247e-06\n",
      "Epoch =  379 Batch =  0 Loss =  25.14196646676586 Gradient_max =  0.24835578796498214 learning rate ratio =  2.661305037524942e-06\n",
      "Epoch =  380 Batch =  0 Loss =  25.116016784469004 Gradient_max =  0.24812830507076034 learning rate ratio =  2.64979258234124e-06\n",
      "Epoch =  381 Batch =  0 Loss =  25.090236517634843 Gradient_max =  0.24790189188411882 learning rate ratio =  2.638314298270566e-06\n",
      "Epoch =  382 Batch =  0 Loss =  25.064624892841017 Gradient_max =  0.24767654642543582 learning rate ratio =  2.6268776521568375e-06\n",
      "Epoch =  383 Batch =  0 Loss =  25.03918072151948 Gradient_max =  0.2474522635824341 learning rate ratio =  2.615482750194764e-06\n",
      "Epoch =  384 Batch =  0 Loss =  25.01390246969884 Gradient_max =  0.24722903557643944 learning rate ratio =  2.6041296078260826e-06\n",
      "Epoch =  385 Batch =  0 Loss =  24.9887890402741 Gradient_max =  0.24700685773974573 learning rate ratio =  2.5928141889100956e-06\n",
      "Epoch =  386 Batch =  0 Loss =  24.963839258954263 Gradient_max =  0.24678572496458 learning rate ratio =  2.581540468085595e-06\n",
      "Epoch =  387 Batch =  0 Loss =  24.939052039957907 Gradient_max =  0.24656563261738407 learning rate ratio =  2.5702811698965187e-06\n",
      "Epoch =  388 Batch =  0 Loss =  24.914426237063875 Gradient_max =  0.24634657565326537 learning rate ratio =  2.559063767439192e-06\n",
      "Epoch =  389 Batch =  0 Loss =  24.88996074557315 Gradient_max =  0.2461285492695085 learning rate ratio =  2.5478885829524852e-06\n",
      "Epoch =  390 Batch =  0 Loss =  24.86565446893485 Gradient_max =  0.24591154869663923 learning rate ratio =  2.536737089339051e-06\n",
      "Epoch =  391 Batch =  0 Loss =  24.84150633158415 Gradient_max =  0.24569556928518227 learning rate ratio =  2.5256212585217022e-06\n",
      "Epoch =  392 Batch =  0 Loss =  24.817515219851504 Gradient_max =  0.2454806059984186 learning rate ratio =  2.514547896061564e-06\n",
      "Epoch =  393 Batch =  0 Loss =  24.793680044872062 Gradient_max =  0.24526665394238178 learning rate ratio =  2.503517071090187e-06\n",
      "Epoch =  394 Batch =  0 Loss =  24.769999756907342 Gradient_max =  0.2450537084366443 learning rate ratio =  2.492528770515188e-06\n",
      "Epoch =  395 Batch =  0 Loss =  24.74647401594518 Gradient_max =  0.24484177007007288 learning rate ratio =  2.2255717471711104e-06\n",
      "Epoch =  396 Batch =  0 Loss =  24.72310125798127 Gradient_max =  0.24463083028051935 learning rate ratio =  2.215772832882527e-06\n",
      "Epoch =  397 Batch =  0 Loss =  24.699880243288295 Gradient_max =  0.2444208828170648 learning rate ratio =  2.2060156790383858e-06\n",
      "Epoch =  398 Batch =  0 Loss =  24.676809908386385 Gradient_max =  0.24421192282493728 learning rate ratio =  2.1963002092921627e-06\n",
      "Epoch =  399 Batch =  0 Loss =  24.65388923915082 Gradient_max =  0.24400394570893724 learning rate ratio =  2.1866263488775937e-06\n",
      "Epoch =  400 Batch =  0 Loss =  24.631117455600275 Gradient_max =  0.24379694873975705 learning rate ratio =  2.176994021445651e-06\n",
      "Epoch =  401 Batch =  0 Loss =  24.608493282200453 Gradient_max =  0.24359092515301647 learning rate ratio =  2.1674031481784844e-06\n",
      "Epoch =  402 Batch =  0 Loss =  24.586015703901992 Gradient_max =  0.24338587019368751 learning rate ratio =  2.1578491570626968e-06\n",
      "Epoch =  403 Batch =  0 Loss =  24.5636837123982 Gradient_max =  0.24318177912409733 learning rate ratio =  2.1483364284088355e-06\n",
      "Epoch =  404 Batch =  0 Loss =  24.541496335490436 Gradient_max =  0.2429786474263645 learning rate ratio =  2.1388649776912766e-06\n",
      "Epoch =  405 Batch =  0 Loss =  24.51945256762581 Gradient_max =  0.242776470345621 learning rate ratio =  2.1294347226258683e-06\n",
      "Epoch =  406 Batch =  0 Loss =  24.497551449600962 Gradient_max =  0.2425752433232745 learning rate ratio =  2.1200455763289755e-06\n",
      "Epoch =  407 Batch =  0 Loss =  24.47579199086573 Gradient_max =  0.24237496167245323 learning rate ratio =  2.1106974534640715e-06\n",
      "Epoch =  408 Batch =  0 Loss =  24.454173233975574 Gradient_max =  0.24217562085276537 learning rate ratio =  2.101390266173117e-06\n",
      "Epoch =  409 Batch =  0 Loss =  24.43269421965208 Gradient_max =  0.24197721626030758 learning rate ratio =  2.0921239257351383e-06\n",
      "Epoch =  410 Batch =  0 Loss =  24.411354018416336 Gradient_max =  0.2417797434592815 learning rate ratio =  2.082898339473763e-06\n",
      "Epoch =  411 Batch =  0 Loss =  24.390151667496323 Gradient_max =  0.2415831977661326 learning rate ratio =  2.0737134193127616e-06\n",
      "Epoch =  412 Batch =  0 Loss =  24.36908622407406 Gradient_max =  0.24138757458723897 learning rate ratio =  2.064569073817931e-06\n",
      "Epoch =  413 Batch =  0 Loss =  24.348156771813642 Gradient_max =  0.24119286945812962 learning rate ratio =  2.055465209984685e-06\n",
      "Epoch =  414 Batch =  0 Loss =  24.32736237658989 Gradient_max =  0.2409990778124357 learning rate ratio =  2.0464017338071583e-06\n",
      "Epoch =  415 Batch =  0 Loss =  24.30670212674619 Gradient_max =  0.24080619518643892 learning rate ratio =  2.0373785497518114e-06\n",
      "Epoch =  416 Batch =  0 Loss =  24.28617513628338 Gradient_max =  0.24061421723309676 learning rate ratio =  2.0283921537219467e-06\n",
      "Epoch =  417 Batch =  0 Loss =  24.265780490772162 Gradient_max =  0.24042313939964324 learning rate ratio =  2.019442596775157e-06\n",
      "Epoch =  418 Batch =  0 Loss =  24.245517311068216 Gradient_max =  0.24023295737905231 learning rate ratio =  2.0105311913366077e-06\n",
      "Epoch =  419 Batch =  0 Loss =  24.225384763817456 Gradient_max =  0.24004366727718804 learning rate ratio =  1.8241190089672493e-06\n",
      "Epoch =  420 Batch =  0 Loss =  24.20538213363039 Gradient_max =  0.23985526611393007 learning rate ratio =  1.8162182568358714e-06\n",
      "Epoch =  421 Batch =  0 Loss =  24.185508304259052 Gradient_max =  0.2396677473497234 learning rate ratio =  1.808353070419296e-06\n",
      "Epoch =  422 Batch =  0 Loss =  24.16576238278256 Gradient_max =  0.23948110645550616 learning rate ratio =  1.800523384722487e-06\n",
      "Epoch =  423 Batch =  0 Loss =  24.146143535139064 Gradient_max =  0.23929533925056026 learning rate ratio =  1.7927291041885427e-06\n",
      "Epoch =  424 Batch =  0 Loss =  24.126650891024948 Gradient_max =  0.23911044129528872 learning rate ratio =  1.78497013773798e-06\n",
      "Epoch =  425 Batch =  0 Loss =  24.10728359265253 Gradient_max =  0.23892640818253708 learning rate ratio =  1.7772463914089648e-06\n",
      "Epoch =  426 Batch =  0 Loss =  24.08804079675939 Gradient_max =  0.23874323559355926 learning rate ratio =  1.769553973727926e-06\n",
      "Epoch =  427 Batch =  0 Loss =  24.06892166842641 Gradient_max =  0.23856091923438333 learning rate ratio =  1.761893949240465e-06\n",
      "Epoch =  428 Batch =  0 Loss =  24.049925374993233 Gradient_max =  0.2383794548448417 learning rate ratio =  1.7542689230589305e-06\n",
      "Epoch =  429 Batch =  0 Loss =  24.031051070742322 Gradient_max =  0.23819883798852023 learning rate ratio =  1.7466788310393384e-06\n",
      "Epoch =  430 Batch =  0 Loss =  24.012297940628116 Gradient_max =  0.23801906442082427 learning rate ratio =  1.739123575804206e-06\n",
      "Epoch =  431 Batch =  0 Loss =  23.993665202855176 Gradient_max =  0.23784013009980398 learning rate ratio =  1.7316030583198699e-06\n",
      "Epoch =  432 Batch =  0 Loss =  23.97515202373092 Gradient_max =  0.23766203066271385 learning rate ratio =  1.7241171796803967e-06\n",
      "Epoch =  433 Batch =  0 Loss =  23.95675760273616 Gradient_max =  0.23748476183906012 learning rate ratio =  1.716665840909703e-06\n",
      "Epoch =  434 Batch =  0 Loss =  23.938481137276334 Gradient_max =  0.23730831939073646 learning rate ratio =  1.7092489420360404e-06\n",
      "Epoch =  435 Batch =  0 Loss =  23.92032183441921 Gradient_max =  0.23713269913295196 learning rate ratio =  1.7018663815690461e-06\n",
      "Epoch =  436 Batch =  0 Loss =  23.902278907181515 Gradient_max =  0.2369578968834058 learning rate ratio =  1.6945180592029614e-06\n",
      "Epoch =  437 Batch =  0 Loss =  23.88435156265779 Gradient_max =  0.23678390841744223 learning rate ratio =  1.6872038735157229e-06\n",
      "Epoch =  438 Batch =  0 Loss =  23.866539025935253 Gradient_max =  0.2366107295876897 learning rate ratio =  1.6799237224451316e-06\n",
      "Epoch =  439 Batch =  0 Loss =  23.848840534318448 Gradient_max =  0.23643835631500937 learning rate ratio =  1.6726775029387294e-06\n",
      "Epoch =  440 Batch =  0 Loss =  23.83125533150038 Gradient_max =  0.23626678452254388 learning rate ratio =  1.6654651122340749e-06\n",
      "Epoch =  441 Batch =  0 Loss =  23.813782658138624 Gradient_max =  0.23609601011497444 learning rate ratio =  1.6582864467010363e-06\n",
      "Epoch =  442 Batch =  0 Loss =  23.796421764218632 Gradient_max =  0.23592602899142232 learning rate ratio =  1.6511414002719552e-06\n",
      "Epoch =  443 Batch =  0 Loss =  23.779171909230655 Gradient_max =  0.2357568371045436 learning rate ratio =  1.6440298710044013e-06\n",
      "Epoch =  444 Batch =  0 Loss =  23.762032333486754 Gradient_max =  0.2355884303295145 learning rate ratio =  1.6369445917666862e-06\n",
      "Epoch =  445 Batch =  0 Loss =  23.74500230134674 Gradient_max =  0.23542080463151485 learning rate ratio =  1.6298925349288573e-06\n",
      "Epoch =  446 Batch =  0 Loss =  23.728081080729872 Gradient_max =  0.2352539559861619 learning rate ratio =  1.622873790592314e-06\n",
      "Epoch =  447 Batch =  0 Loss =  23.711267946213663 Gradient_max =  0.23508788039170753 learning rate ratio =  1.6158882539771985e-06\n",
      "Epoch =  448 Batch =  0 Loss =  23.694562173031084 Gradient_max =  0.23492257384034115 learning rate ratio =  1.6089358184174006e-06\n",
      "Epoch =  449 Batch =  0 Loss =  23.677963049929478 Gradient_max =  0.23475803240198792 learning rate ratio =  1.6020163762835083e-06\n",
      "Epoch =  450 Batch =  0 Loss =  23.66146986016875 Gradient_max =  0.23459425206880713 learning rate ratio =  1.5951298197324345e-06\n",
      "Epoch =  451 Batch =  0 Loss =  23.645081901941534 Gradient_max =  0.2344312289181184 learning rate ratio =  1.588276039734059e-06\n",
      "Epoch =  452 Batch =  0 Loss =  23.62879847137242 Gradient_max =  0.23426895900771288 learning rate ratio =  1.5814549282684662e-06\n",
      "Epoch =  453 Batch =  0 Loss =  23.612618887109974 Gradient_max =  0.23410743853475813 learning rate ratio =  1.5746613130675474e-06\n",
      "Epoch =  454 Batch =  0 Loss =  23.59654244658684 Gradient_max =  0.23394666351534416 learning rate ratio =  1.5679001160651958e-06\n",
      "Epoch =  455 Batch =  0 Loss =  23.58056847847232 Gradient_max =  0.2337866301746076 learning rate ratio =  1.5611713375327063e-06\n",
      "Epoch =  456 Batch =  0 Loss =  23.56469628807929 Gradient_max =  0.2336273345482535 learning rate ratio =  1.5544748692658609e-06\n",
      "Epoch =  457 Batch =  0 Loss =  23.54892519767147 Gradient_max =  0.23346877277603317 learning rate ratio =  1.547810600560912e-06\n",
      "Epoch =  458 Batch =  0 Loss =  23.53325454642041 Gradient_max =  0.23331094107403832 learning rate ratio =  1.5411784195183271e-06\n",
      "Epoch =  459 Batch =  0 Loss =  23.51768366904361 Gradient_max =  0.23315383565795167 learning rate ratio =  1.5345782151384117e-06\n",
      "Epoch =  460 Batch =  0 Loss =  23.50221189372562 Gradient_max =  0.2329974526595526 learning rate ratio =  1.528009876413802e-06\n",
      "Epoch =  461 Batch =  0 Loss =  23.48683857013094 Gradient_max =  0.2328417883282821 learning rate ratio =  1.5214732905801988e-06\n",
      "Epoch =  462 Batch =  0 Loss =  23.471563046658424 Gradient_max =  0.23268683892308373 learning rate ratio =  1.5149683466378517e-06\n",
      "Epoch =  463 Batch =  0 Loss =  23.456384669509468 Gradient_max =  0.2325326006409023 learning rate ratio =  1.5084949327842194e-06\n",
      "Epoch =  464 Batch =  0 Loss =  23.44130279889519 Gradient_max =  0.23237906977160894 learning rate ratio =  1.5020529366138248e-06\n",
      "Epoch =  465 Batch =  0 Loss =  23.426316794710836 Gradient_max =  0.23222624258132907 learning rate ratio =  1.495642245925681e-06\n",
      "Epoch =  466 Batch =  0 Loss =  23.411426022542262 Gradient_max =  0.2320741153614278 learning rate ratio =  1.4892627482976015e-06\n",
      "Epoch =  467 Batch =  0 Loss =  23.396629853471197 Gradient_max =  0.23192268442722508 learning rate ratio =  1.4829143311076344e-06\n",
      "Epoch =  468 Batch =  0 Loss =  23.38192767640744 Gradient_max =  0.2317719461642705 learning rate ratio =  1.4765968816100928e-06\n",
      "Epoch =  469 Batch =  0 Loss =  23.36731887700271 Gradient_max =  0.231621896942781 learning rate ratio =  1.4703102869406258e-06\n",
      "Epoch =  470 Batch =  0 Loss =  23.352802827793482 Gradient_max =  0.23147253309934962 learning rate ratio =  1.4640544335212805e-06\n",
      "Epoch =  471 Batch =  0 Loss =  23.33837892733618 Gradient_max =  0.23132385106128223 learning rate ratio =  1.4578292074649345e-06\n",
      "Epoch =  472 Batch =  0 Loss =  23.324046560579646 Gradient_max =  0.23117584717166698 learning rate ratio =  1.4516344963675818e-06\n",
      "Epoch =  473 Batch =  0 Loss =  23.30980512343299 Gradient_max =  0.23102851785082631 learning rate ratio =  1.445467264878574e-06\n",
      "Epoch =  474 Batch =  0 Loss =  23.295654009842504 Gradient_max =  0.23088185946728307 learning rate ratio =  1.439330246311208e-06\n",
      "Epoch =  475 Batch =  0 Loss =  23.281592628937563 Gradient_max =  0.23073586847369712 learning rate ratio =  1.4332234501008402e-06\n",
      "Epoch =  476 Batch =  0 Loss =  23.267620388224127 Gradient_max =  0.23059054131731768 learning rate ratio =  1.4271467637532147e-06\n",
      "Epoch =  477 Batch =  0 Loss =  23.25373670073964 Gradient_max =  0.23044587446673384 learning rate ratio =  1.4211000732835047e-06\n",
      "Epoch =  478 Batch =  0 Loss =  23.239941078194455 Gradient_max =  0.23030186497710847 learning rate ratio =  1.1811513015818988e-06\n",
      "Epoch =  479 Batch =  0 Loss =  23.22623294260795 Gradient_max =  0.23015850935158735 learning rate ratio =  1.1766930718564738e-06\n",
      "Epoch =  480 Batch =  0 Loss =  23.212611625028497 Gradient_max =  0.23001580353097753 learning rate ratio =  1.1722560215266538e-06\n",
      "Epoch =  481 Batch =  0 Loss =  23.19907655618245 Gradient_max =  0.22987374405194186 learning rate ratio =  1.1678400670141216e-06\n",
      "Epoch =  482 Batch =  0 Loss =  23.18562717302534 Gradient_max =  0.22973232748043956 learning rate ratio =  1.163445124856922e-06\n",
      "Epoch =  483 Batch =  0 Loss =  23.172262914961195 Gradient_max =  0.2295915503854734 learning rate ratio =  1.1590711116625026e-06\n",
      "Epoch =  484 Batch =  0 Loss =  23.15898322602373 Gradient_max =  0.2294514093699874 learning rate ratio =  1.1547179442562207e-06\n",
      "Epoch =  485 Batch =  0 Loss =  23.14578754895981 Gradient_max =  0.2293119010015593 learning rate ratio =  1.1503855395492325e-06\n",
      "Epoch =  486 Batch =  0 Loss =  23.13267534024774 Gradient_max =  0.22917302194442535 learning rate ratio =  1.146073814575577e-06\n",
      "Epoch =  487 Batch =  0 Loss =  23.11964605834618 Gradient_max =  0.22903476885811203 learning rate ratio =  1.1417826864979312e-06\n",
      "Epoch =  488 Batch =  0 Loss =  23.106699151214 Gradient_max =  0.2288971383066843 learning rate ratio =  1.1375120726142665e-06\n",
      "Epoch =  489 Batch =  0 Loss =  23.093834080781193 Gradient_max =  0.22876012695026302 learning rate ratio =  1.1332618903610415e-06\n",
      "Epoch =  490 Batch =  0 Loss =  23.081050312939798 Gradient_max =  0.22862373146570966 learning rate ratio =  1.1290320573138956e-06\n",
      "Epoch =  491 Batch =  0 Loss =  23.06834732421751 Gradient_max =  0.2284879485800393 learning rate ratio =  1.1248224905377106e-06\n",
      "Epoch =  492 Batch =  0 Loss =  23.055724582604213 Gradient_max =  0.2283527749736934 learning rate ratio =  1.1206331084111097e-06\n",
      "Epoch =  493 Batch =  0 Loss =  23.04318156530271 Gradient_max =  0.22821820737579288 learning rate ratio =  1.1164638290960806e-06\n",
      "Epoch =  494 Batch =  0 Loss =  23.030717751560843 Gradient_max =  0.22808424251237366 learning rate ratio =  1.1123145707509183e-06\n",
      "Epoch =  495 Batch =  0 Loss =  23.01833262643609 Gradient_max =  0.22795087714248682 learning rate ratio =  1.108185251683818e-06\n",
      "Epoch =  496 Batch =  0 Loss =  23.00602567806587 Gradient_max =  0.227818108036118 learning rate ratio =  1.1040757903565827e-06\n",
      "Epoch =  497 Batch =  0 Loss =  22.993796400417622 Gradient_max =  0.2276859319954996 learning rate ratio =  1.0999861053332848e-06\n",
      "Epoch =  498 Batch =  0 Loss =  22.98164428737279 Gradient_max =  0.2275543458096439 learning rate ratio =  1.095916115419996e-06\n",
      "Epoch =  499 Batch =  0 Loss =  22.969568839208648 Gradient_max =  0.22742564531915513 learning rate ratio =  1.0918651348982846e-06\n",
      "Epoch =  500 Batch =  0 Loss =  22.957569556501106 Gradient_max =  0.22731915528142685 learning rate ratio =  1.087833404184267e-06\n",
      "Epoch =  501 Batch =  0 Loss =  22.945645942511792 Gradient_max =  0.22721312831695897 learning rate ratio =  1.083821135482506e-06\n",
      "Epoch =  502 Batch =  0 Loss =  22.933797511645857 Gradient_max =  0.2271075616209378 learning rate ratio =  1.0798267743781561e-06\n",
      "Epoch =  503 Batch =  0 Loss =  22.922023777362714 Gradient_max =  0.2270024523895104 learning rate ratio =  1.0758510444393702e-06\n",
      "Epoch =  504 Batch =  0 Loss =  22.910324256510933 Gradient_max =  0.2268977978396411 learning rate ratio =  1.0718945525919109e-06\n",
      "Epoch =  505 Batch =  0 Loss =  22.89869846503283 Gradient_max =  0.22679359518072753 learning rate ratio =  1.0679572365406114e-06\n",
      "Epoch =  506 Batch =  0 Loss =  22.887145921956055 Gradient_max =  0.22668984163780403 learning rate ratio =  1.0640390162442184e-06\n",
      "Epoch =  507 Batch =  0 Loss =  22.87566615288617 Gradient_max =  0.22658653446926608 learning rate ratio =  1.0601398115080782e-06\n",
      "Epoch =  508 Batch =  0 Loss =  22.864258687589356 Gradient_max =  0.22648367095488892 learning rate ratio =  1.0562595423042497e-06\n",
      "Epoch =  509 Batch =  0 Loss =  22.852923070287034 Gradient_max =  0.22638124848525118 learning rate ratio =  1.0523981287734796e-06\n",
      "Epoch =  510 Batch =  0 Loss =  22.841658828668855 Gradient_max =  0.22627926430751183 learning rate ratio =  1.0485554912902236e-06\n",
      "Epoch =  511 Batch =  0 Loss =  22.830465497657503 Gradient_max =  0.226177715713735 learning rate ratio =  1.0447315503919582e-06\n",
      "Epoch =  512 Batch =  0 Loss =  22.8193426227606 Gradient_max =  0.2260766000769058 learning rate ratio =  1.0409262268060585e-06\n",
      "Epoch =  513 Batch =  0 Loss =  22.808289746194337 Gradient_max =  0.22597591473019427 learning rate ratio =  1.037139441450496e-06\n",
      "Epoch =  514 Batch =  0 Loss =  22.797306419442744 Gradient_max =  0.2258756570653982 learning rate ratio =  1.0333711153864851e-06\n",
      "Epoch =  515 Batch =  0 Loss =  22.786392191357642 Gradient_max =  0.2257758244626134 learning rate ratio =  1.0296211699696205e-06\n",
      "Epoch =  516 Batch =  0 Loss =  22.775546619136964 Gradient_max =  0.22567641434208435 learning rate ratio =  1.0258890379414607e-06\n",
      "Epoch =  517 Batch =  0 Loss =  22.76476926044954 Gradient_max =  0.22557742412958423 learning rate ratio =  1.0221748084927439e-06\n",
      "Epoch =  518 Batch =  0 Loss =  22.754059674114067 Gradient_max =  0.22547885125912162 learning rate ratio =  1.0184787331110076e-06\n",
      "Epoch =  519 Batch =  0 Loss =  22.743417426998302 Gradient_max =  0.22538069321448728 learning rate ratio =  1.0148007376835766e-06\n",
      "Epoch =  520 Batch =  0 Loss =  22.732842084941318 Gradient_max =  0.22528294745403665 learning rate ratio =  1.0111407443950364e-06\n",
      "Epoch =  521 Batch =  0 Loss =  22.722333216522166 Gradient_max =  0.22518561146071697 learning rate ratio =  1.007498675631977e-06\n",
      "Epoch =  522 Batch =  0 Loss =  22.711890396261037 Gradient_max =  0.22508868274850186 learning rate ratio =  1.0038744539438264e-06\n",
      "Epoch =  523 Batch =  0 Loss =  22.70151320492038 Gradient_max =  0.22499215886054608 learning rate ratio =  1.0002675038834312e-06\n",
      "Epoch =  524 Batch =  0 Loss =  22.691201220705235 Gradient_max =  0.22489603733924984 learning rate ratio =  9.966779738044627e-07\n",
      "Epoch =  525 Batch =  0 Loss =  22.68095402036382 Gradient_max =  0.22480031571026265 learning rate ratio =  9.931060677576013e-07\n",
      "Epoch =  526 Batch =  0 Loss =  22.670771190676774 Gradient_max =  0.22470499154928264 learning rate ratio =  9.89551712139759e-07\n",
      "Epoch =  527 Batch =  0 Loss =  22.660652514408838 Gradient_max =  0.22461006361040875 learning rate ratio =  8.896413902840862e-07\n",
      "Epoch =  528 Batch =  0 Loss =  22.65059743056815 Gradient_max =  0.2245155285689539 learning rate ratio =  8.865833153839722e-07\n",
      "Epoch =  529 Batch =  0 Loss =  22.640605482480225 Gradient_max =  0.22442138375932513 learning rate ratio =  8.835404929177981e-07\n",
      "Epoch =  530 Batch =  0 Loss =  22.63067626800377 Gradient_max =  0.22432762681973922 learning rate ratio =  8.805128669982202e-07\n",
      "Epoch =  531 Batch =  0 Loss =  22.620809385960374 Gradient_max =  0.22423425540287595 learning rate ratio =  8.775003696293416e-07\n",
      "Epoch =  532 Batch =  0 Loss =  22.6110044388363 Gradient_max =  0.2241412671635874 learning rate ratio =  8.745029326041797e-07\n",
      "Epoch =  533 Batch =  0 Loss =  22.60126102775206 Gradient_max =  0.22404865975908855 learning rate ratio =  8.715204883994263e-07\n",
      "Epoch =  534 Batch =  0 Loss =  22.59157876216716 Gradient_max =  0.2239564308989767 learning rate ratio =  8.685529694706409e-07\n",
      "Epoch =  535 Batch =  0 Loss =  22.58195725263415 Gradient_max =  0.22386457827655684 learning rate ratio =  8.656000354864127e-07\n",
      "Epoch =  536 Batch =  0 Loss =  22.57239610829527 Gradient_max =  0.22377309959649477 learning rate ratio =  8.626618886384717e-07\n",
      "Epoch =  537 Batch =  0 Loss =  22.562894944904745 Gradient_max =  0.22368199259379073 learning rate ratio =  8.597384697427256e-07\n",
      "Epoch =  538 Batch =  0 Loss =  22.553453384804452 Gradient_max =  0.2235912550394257 learning rate ratio =  8.56829711934563e-07\n",
      "Epoch =  539 Batch =  0 Loss =  22.54407104947826 Gradient_max =  0.2235008846976386 learning rate ratio =  8.539351475570047e-07\n",
      "Epoch =  540 Batch =  0 Loss =  22.534747556704897 Gradient_max =  0.22341087931689388 learning rate ratio =  8.51055078256771e-07\n",
      "Epoch =  541 Batch =  0 Loss =  22.52548253158295 Gradient_max =  0.22332123668715384 learning rate ratio =  8.48189477421337e-07\n",
      "Epoch =  542 Batch =  0 Loss =  22.516275602935927 Gradient_max =  0.22323195461673537 learning rate ratio =  8.453382795539251e-07\n",
      "Epoch =  543 Batch =  0 Loss =  22.507126399373277 Gradient_max =  0.22314303090431353 learning rate ratio =  8.425014189086273e-07\n",
      "Epoch =  544 Batch =  0 Loss =  22.498034556202263 Gradient_max =  0.22305446339854665 learning rate ratio =  8.396788299505133e-07\n",
      "Epoch =  545 Batch =  0 Loss =  22.488999706842392 Gradient_max =  0.22296624992329192 learning rate ratio =  8.368704473621075e-07\n",
      "Epoch =  546 Batch =  0 Loss =  22.480021489375968 Gradient_max =  0.22287838833506476 learning rate ratio =  8.340762060436113e-07\n",
      "Epoch =  547 Batch =  0 Loss =  22.471099544391322 Gradient_max =  0.22279087650422535 learning rate ratio =  8.312960411131538e-07\n",
      "Epoch =  548 Batch =  0 Loss =  22.462233514924776 Gradient_max =  0.22270371231454578 learning rate ratio =  8.285298879071328e-07\n",
      "Epoch =  549 Batch =  0 Loss =  22.453423047817353 Gradient_max =  0.22261689366997384 learning rate ratio =  8.257776819618162e-07\n",
      "Epoch =  550 Batch =  0 Loss =  22.44466778957627 Gradient_max =  0.22253041847401211 learning rate ratio =  8.230393590696158e-07\n",
      "Epoch =  551 Batch =  0 Loss =  22.435967392688102 Gradient_max =  0.2224442846612355 learning rate ratio =  8.203148550711615e-07\n",
      "Epoch =  552 Batch =  0 Loss =  22.427321508269205 Gradient_max =  0.22235849016056142 learning rate ratio =  8.176041062848482e-07\n",
      "Epoch =  553 Batch =  0 Loss =  22.41872979057089 Gradient_max =  0.22227303291778153 learning rate ratio =  8.149070491944923e-07\n",
      "Epoch =  554 Batch =  0 Loss =  22.41019189693276 Gradient_max =  0.22218791089533568 learning rate ratio =  8.12223620452826e-07\n",
      "Epoch =  555 Batch =  0 Loss =  22.4017074879955 Gradient_max =  0.22210312207423374 learning rate ratio =  8.095537569320324e-07\n",
      "Epoch =  556 Batch =  0 Loss =  22.39327622478696 Gradient_max =  0.22201866443694226 learning rate ratio =  8.068973957246183e-07\n",
      "Epoch =  557 Batch =  0 Loss =  22.384897771543436 Gradient_max =  0.22193453598400442 learning rate ratio =  8.042544741438177e-07\n",
      "Epoch =  558 Batch =  0 Loss =  22.37657179480827 Gradient_max =  0.2218507347287523 learning rate ratio =  8.016249297236027e-07\n",
      "Epoch =  559 Batch =  0 Loss =  22.368297965313122 Gradient_max =  0.22176725871394087 learning rate ratio =  7.990087002187759e-07\n",
      "Epoch =  560 Batch =  0 Loss =  22.36007595227844 Gradient_max =  0.2216841059619068 learning rate ratio =  7.964057236047946e-07\n",
      "Epoch =  561 Batch =  0 Loss =  22.351905428821503 Gradient_max =  0.22160127452199893 learning rate ratio =  7.938159380786507e-07\n",
      "Epoch =  562 Batch =  0 Loss =  22.34378612006133 Gradient_max =  0.2215187626272519 learning rate ratio =  7.91239276316739e-07\n",
      "Epoch =  563 Batch =  0 Loss =  22.335717681564933 Gradient_max =  0.22143656828126634 learning rate ratio =  7.886756797245172e-07\n",
      "Epoch =  564 Batch =  0 Loss =  22.32769976738276 Gradient_max =  0.22135468949356146 learning rate ratio =  7.861250903367579e-07\n",
      "Epoch =  565 Batch =  0 Loss =  22.319732059519456 Gradient_max =  0.22127312435998117 learning rate ratio =  7.83587447224403e-07\n",
      "Epoch =  566 Batch =  0 Loss =  22.311814299131484 Gradient_max =  0.22119187145713504 learning rate ratio =  7.810626896957291e-07\n",
      "Epoch =  567 Batch =  0 Loss =  22.30394613672578 Gradient_max =  0.22111092861810916 learning rate ratio =  7.785507572736237e-07\n",
      "Epoch =  568 Batch =  0 Loss =  22.296127235447933 Gradient_max =  0.22103029377209524 learning rate ratio =  7.760515897018348e-07\n",
      "Epoch =  569 Batch =  0 Loss =  22.288357285779682 Gradient_max =  0.22094996506575532 learning rate ratio =  7.735651269458511e-07\n",
      "Epoch =  570 Batch =  0 Loss =  22.2806359803074 Gradient_max =  0.2208699406576191 learning rate ratio =  7.710913091927709e-07\n",
      "Epoch =  571 Batch =  0 Loss =  22.272963014010603 Gradient_max =  0.22079021871979476 learning rate ratio =  7.686300768511976e-07\n",
      "Epoch =  572 Batch =  0 Loss =  22.265338083615305 Gradient_max =  0.22071079743397665 learning rate ratio =  7.661813705512762e-07\n",
      "Epoch =  573 Batch =  0 Loss =  22.257760887888185 Gradient_max =  0.22063167499340477 learning rate ratio =  7.637451311446228e-07\n",
      "Epoch =  574 Batch =  0 Loss =  22.250231127442703 Gradient_max =  0.22055284960232857 learning rate ratio =  7.61321299704346e-07\n",
      "Epoch =  575 Batch =  0 Loss =  22.242748538908906 Gradient_max =  0.22047431960786554 learning rate ratio =  7.589098146320781e-07\n",
      "Epoch =  576 Batch =  0 Loss =  22.235312828643742 Gradient_max =  0.22039608323662535 learning rate ratio =  7.565106172549065e-07\n",
      "Epoch =  577 Batch =  0 Loss =  22.227923668133638 Gradient_max =  0.22031813859703003 learning rate ratio =  7.541235549084949e-07\n",
      "Epoch =  578 Batch =  0 Loss =  22.22058076537026 Gradient_max =  0.22024048393534676 learning rate ratio =  7.517486402902776e-07\n",
      "Epoch =  579 Batch =  0 Loss =  22.213283830570322 Gradient_max =  0.2201631175100197 learning rate ratio =  7.493858441297811e-07\n",
      "Epoch =  580 Batch =  0 Loss =  22.20603257736171 Gradient_max =  0.2200860376013144 learning rate ratio =  7.470351091395851e-07\n",
      "Epoch =  581 Batch =  0 Loss =  22.198826719695983 Gradient_max =  0.22000924248637593 learning rate ratio =  7.446963779169596e-07\n",
      "Epoch =  582 Batch =  0 Loss =  22.191665973496523 Gradient_max =  0.21993273045373224 learning rate ratio =  7.423695932760453e-07\n",
      "Epoch =  583 Batch =  0 Loss =  22.18455005682904 Gradient_max =  0.21985649980480018 learning rate ratio =  7.40054698251681e-07\n",
      "Epoch =  584 Batch =  0 Loss =  22.177478690516132 Gradient_max =  0.2197805488593713 learning rate ratio =  7.377516360991931e-07\n",
      "Epoch =  585 Batch =  0 Loss =  22.170451596453873 Gradient_max =  0.21970487594087712 learning rate ratio =  7.354603502940679e-07\n",
      "Epoch =  586 Batch =  0 Loss =  22.16346850007104 Gradient_max =  0.21962947939443936 learning rate ratio =  7.33180784521221e-07\n",
      "Epoch =  587 Batch =  0 Loss =  22.156529125771815 Gradient_max =  0.21955435755729022 learning rate ratio =  7.309128827055092e-07\n",
      "Epoch =  588 Batch =  0 Loss =  22.14963320066338 Gradient_max =  0.2194795087819857 learning rate ratio =  7.286565889833415e-07\n",
      "Epoch =  589 Batch =  0 Loss =  22.142780454088854 Gradient_max =  0.2194049314347113 learning rate ratio =  7.264118477093162e-07\n",
      "Epoch =  590 Batch =  0 Loss =  22.135970617113735 Gradient_max =  0.21933062389124278 learning rate ratio =  7.241786034572192e-07\n",
      "Epoch =  591 Batch =  0 Loss =  22.1292034243566 Gradient_max =  0.21925658455301886 learning rate ratio =  7.219568010197016e-07\n",
      "Epoch =  592 Batch =  0 Loss =  22.122478609508597 Gradient_max =  0.21918281180791468 learning rate ratio =  7.197463854078161e-07\n",
      "Epoch =  593 Batch =  0 Loss =  22.115795908499297 Gradient_max =  0.21910930405807189 learning rate ratio =  7.175473018512422e-07\n",
      "Epoch =  594 Batch =  0 Loss =  22.109155059595132 Gradient_max =  0.219036059720788 learning rate ratio =  7.153594957978719e-07\n",
      "Epoch =  595 Batch =  0 Loss =  22.102555802805824 Gradient_max =  0.2189630772233622 learning rate ratio =  7.131829129134215e-07\n",
      "Epoch =  596 Batch =  0 Loss =  22.09599787986503 Gradient_max =  0.21889035500296994 learning rate ratio =  7.110174990811382e-07\n",
      "Epoch =  597 Batch =  0 Loss =  22.089481034217915 Gradient_max =  0.218817891506598 learning rate ratio =  7.088632004014957e-07\n",
      "Epoch =  598 Batch =  0 Loss =  22.083005011008876 Gradient_max =  0.2187456851909822 learning rate ratio =  7.067199631918837e-07\n",
      "Epoch =  599 Batch =  0 Loss =  22.076569558069856 Gradient_max =  0.21867373453130784 learning rate ratio =  7.045877339862092e-07\n",
      "Epoch =  600 Batch =  0 Loss =  22.070174423085255 Gradient_max =  0.21860203799641667 learning rate ratio =  7.024664595345802e-07\n",
      "Epoch =  601 Batch =  0 Loss =  22.063819356271278 Gradient_max =  0.21853059407162853 learning rate ratio =  7.003560868031541e-07\n",
      "Epoch =  602 Batch =  0 Loss =  22.057504110970363 Gradient_max =  0.21845940125950117 learning rate ratio =  6.982565629566651e-07\n",
      "Epoch =  603 Batch =  0 Loss =  22.05122843890371 Gradient_max =  0.21838845805580065 learning rate ratio =  6.961678354086051e-07\n",
      "Epoch =  604 Batch =  0 Loss =  22.04499209509375 Gradient_max =  0.2183177629741251 learning rate ratio =  6.940898517715513e-07\n",
      "Epoch =  605 Batch =  0 Loss =  22.03879483716122 Gradient_max =  0.21824731454572702 learning rate ratio =  6.920225598718305e-07\n",
      "Epoch =  606 Batch =  0 Loss =  22.032636422641076 Gradient_max =  0.21817711129633374 learning rate ratio =  6.899659077499236e-07\n",
      "Epoch =  607 Batch =  0 Loss =  22.02651661256295 Gradient_max =  0.21810715177383194 learning rate ratio =  6.879198436506819e-07\n",
      "Epoch =  608 Batch =  0 Loss =  22.02043516716796 Gradient_max =  0.21803743452184426 learning rate ratio =  6.858843160511413e-07\n",
      "Epoch =  609 Batch =  0 Loss =  22.01439184944309 Gradient_max =  0.21796795809977226 learning rate ratio =  6.838592736321936e-07\n",
      "Epoch =  610 Batch =  0 Loss =  22.00838642400253 Gradient_max =  0.2178987210765552 learning rate ratio =  6.818446652871606e-07\n",
      "Epoch =  611 Batch =  0 Loss =  22.002418657837836 Gradient_max =  0.21782972203420442 learning rate ratio =  6.798404401133888e-07\n",
      "Epoch =  612 Batch =  0 Loss =  21.996488317950394 Gradient_max =  0.21776095955606203 learning rate ratio =  6.778465474349888e-07\n",
      "Epoch =  613 Batch =  0 Loss =  21.990595173423 Gradient_max =  0.2176924322370707 learning rate ratio =  6.758629367820067e-07\n",
      "Epoch =  614 Batch =  0 Loss =  21.984738995606676 Gradient_max =  0.21762413868533956 learning rate ratio =  6.738895578766215e-07\n",
      "Epoch =  615 Batch =  0 Loss =  21.978919556142735 Gradient_max =  0.21755607751040457 learning rate ratio =  6.719263606863702e-07\n",
      "Epoch =  616 Batch =  0 Loss =  21.973136628759555 Gradient_max =  0.21748824733404373 learning rate ratio =  6.699732953717933e-07\n",
      "Epoch =  617 Batch =  0 Loss =  21.96738998890584 Gradient_max =  0.21742064678869052 learning rate ratio =  6.680303123026428e-07\n",
      "Epoch =  618 Batch =  0 Loss =  21.961679414188204 Gradient_max =  0.2173532745207708 learning rate ratio =  6.660973620577428e-07\n",
      "Epoch =  619 Batch =  0 Loss =  21.956004681649418 Gradient_max =  0.21728612916854473 learning rate ratio =  6.641743954246654e-07\n",
      "Epoch =  620 Batch =  0 Loss =  21.950365570866794 Gradient_max =  0.21721920938777103 learning rate ratio =  6.622613633993814e-07\n",
      "Epoch =  621 Batch =  0 Loss =  21.94476186313123 Gradient_max =  0.2171525138449157 learning rate ratio =  6.603582171856798e-07\n",
      "Epoch =  622 Batch =  0 Loss =  21.939193342146936 Gradient_max =  0.21708604122337813 learning rate ratio =  6.584649081945814e-07\n",
      "Epoch =  623 Batch =  0 Loss =  21.93365979037474 Gradient_max =  0.2170197901914951 learning rate ratio =  6.565813880439103e-07\n",
      "Epoch =  624 Batch =  0 Loss =  21.928160993106804 Gradient_max =  0.2169537594382888 learning rate ratio =  6.547076085580863e-07\n",
      "Epoch =  625 Batch =  0 Loss =  21.92269673720951 Gradient_max =  0.2168879476624554 learning rate ratio =  6.528435217674327e-07\n",
      "Epoch =  626 Batch =  0 Loss =  21.91726681190702 Gradient_max =  0.21682235357929078 learning rate ratio =  6.509890799076509e-07\n",
      "Epoch =  627 Batch =  0 Loss =  21.91187100625624 Gradient_max =  0.21675697589861181 learning rate ratio =  6.491442354192197e-07\n",
      "Epoch =  628 Batch =  0 Loss =  21.90650911029395 Gradient_max =  0.21669181333483623 learning rate ratio =  6.473089409472552e-07\n",
      "Epoch =  629 Batch =  0 Loss =  21.901180916245906 Gradient_max =  0.21662686461757436 learning rate ratio =  6.454831493408803e-07\n",
      "Epoch =  630 Batch =  0 Loss =  21.89588621770109 Gradient_max =  0.21656212848444545 learning rate ratio =  6.436668136526646e-07\n",
      "Epoch =  631 Batch =  0 Loss =  21.890624809592506 Gradient_max =  0.21649760368094215 learning rate ratio =  6.41859887138115e-07\n",
      "Epoch =  632 Batch =  0 Loss =  21.885396488187638 Gradient_max =  0.21643328896037844 learning rate ratio =  6.400623232551646e-07\n",
      "Epoch =  633 Batch =  0 Loss =  21.88020105107912 Gradient_max =  0.21636918308383907 learning rate ratio =  6.382740756636581e-07\n",
      "Epoch =  634 Batch =  0 Loss =  21.875038297175465 Gradient_max =  0.21630528482012765 learning rate ratio =  6.364950982248314e-07\n",
      "Epoch =  635 Batch =  0 Loss =  21.86990802669183 Gradient_max =  0.21624159294571976 learning rate ratio =  6.347253450007904e-07\n",
      "Epoch =  636 Batch =  0 Loss =  21.86481004114093 Gradient_max =  0.2161781062447112 learning rate ratio =  6.329647702539846e-07\n",
      "Epoch =  637 Batch =  0 Loss =  21.859744145163923 Gradient_max =  0.21611482351886452 learning rate ratio =  6.312133284310645e-07\n",
      "Epoch =  638 Batch =  0 Loss =  21.85471014133405 Gradient_max =  0.2160517435592246 learning rate ratio =  6.294709742065586e-07\n",
      "Epoch =  639 Batch =  0 Loss =  21.84970783463599 Gradient_max =  0.21598886517030377 learning rate ratio =  6.277376624434386e-07\n",
      "Epoch =  640 Batch =  0 Loss =  21.844737032624693 Gradient_max =  0.21592618716979786 learning rate ratio =  6.26013193534128e-07\n",
      "Epoch =  641 Batch =  0 Loss =  21.839797543208654 Gradient_max =  0.21586370837933505 learning rate ratio =  6.242975179695835e-07\n",
      "Epoch =  642 Batch =  0 Loss =  21.83488917450278 Gradient_max =  0.2158014276238943 learning rate ratio =  6.225907523774973e-07\n",
      "Epoch =  643 Batch =  0 Loss =  21.83001173730707 Gradient_max =  0.21573934374236114 learning rate ratio =  6.208928555229902e-07\n",
      "Epoch =  644 Batch =  0 Loss =  21.825165042765775 Gradient_max =  0.21567745557545645 learning rate ratio =  6.192037832410565e-07\n",
      "Epoch =  645 Batch =  0 Loss =  21.820348903612654 Gradient_max =  0.21561576197333623 learning rate ratio =  6.175234915164614e-07\n",
      "Epoch =  646 Batch =  0 Loss =  21.81556313384878 Gradient_max =  0.21555426179364723 learning rate ratio =  6.158519365277001e-07\n",
      "Epoch =  647 Batch =  0 Loss =  21.810807548863078 Gradient_max =  0.21549295390203144 learning rate ratio =  6.141890746463585e-07\n",
      "Epoch =  648 Batch =  0 Loss =  21.806081966133316 Gradient_max =  0.21543183717471992 learning rate ratio =  6.125347520749457e-07\n",
      "Epoch =  649 Batch =  0 Loss =  21.801386202014093 Gradient_max =  0.21537091048532667 learning rate ratio =  6.108890311923369e-07\n",
      "Epoch =  650 Batch =  0 Loss =  21.796720075198394 Gradient_max =  0.2153101727193574 learning rate ratio =  6.092518754482946e-07\n",
      "Epoch =  651 Batch =  0 Loss =  21.792083405612416 Gradient_max =  0.21524962276948353 learning rate ratio =  6.07623242045823e-07\n",
      "Epoch =  652 Batch =  0 Loss =  21.78747601501782 Gradient_max =  0.21518925954110313 learning rate ratio =  6.060030883035818e-07\n",
      "Epoch =  653 Batch =  0 Loss =  21.782897725009175 Gradient_max =  0.21512908193497438 learning rate ratio =  6.043913717309805e-07\n",
      "Epoch =  654 Batch =  0 Loss =  21.7783483834748 Gradient_max =  0.215069089017011 learning rate ratio =  6.027880500286678e-07\n",
      "Epoch =  655 Batch =  0 Loss =  21.773827815494766 Gradient_max =  0.21500927970948985 learning rate ratio =  6.011930810829261e-07\n",
      "Epoch =  656 Batch =  0 Loss =  21.76933582092152 Gradient_max =  0.21494965277921488 learning rate ratio =  5.996064229799172e-07\n",
      "Epoch =  657 Batch =  0 Loss =  21.764872226560676 Gradient_max =  0.21489020715978635 learning rate ratio =  5.980280339903479e-07\n",
      "Epoch =  658 Batch =  0 Loss =  21.760436860772845 Gradient_max =  0.2148309417931557 learning rate ratio =  5.964578725686357e-07\n",
      "Epoch =  659 Batch =  0 Loss =  21.756029552176074 Gradient_max =  0.2147718556240288 learning rate ratio =  5.948958973618388e-07\n",
      "Epoch =  660 Batch =  0 Loss =  21.751650130935698 Gradient_max =  0.21471294760559478 learning rate ratio =  5.933420672087431e-07\n",
      "Epoch =  661 Batch =  0 Loss =  21.747298428246186 Gradient_max =  0.21465421669733759 learning rate ratio =  5.917963411319673e-07\n",
      "Epoch =  662 Batch =  0 Loss =  21.742974276133026 Gradient_max =  0.21459566186400025 learning rate ratio =  5.902586783423868e-07\n",
      "Epoch =  663 Batch =  0 Loss =  21.738677507937627 Gradient_max =  0.21453728207785996 learning rate ratio =  5.887290382346099e-07\n",
      "Epoch =  664 Batch =  0 Loss =  21.734407958072204 Gradient_max =  0.2144790763175645 learning rate ratio =  5.872073803884424e-07\n",
      "Epoch =  665 Batch =  0 Loss =  21.730165462009634 Gradient_max =  0.214421043568074 learning rate ratio =  5.856936645683084e-07\n",
      "Epoch =  666 Batch =  0 Loss =  21.725949856276102 Gradient_max =  0.21436318282062267 learning rate ratio =  5.841878507226482e-07\n",
      "Epoch =  667 Batch =  0 Loss =  21.72176097844395 Gradient_max =  0.21430549307267738 learning rate ratio =  5.826898989833093e-07\n",
      "Epoch =  668 Batch =  0 Loss =  21.717598667276405 Gradient_max =  0.2142479733287203 learning rate ratio =  5.811997696589689e-07\n",
      "Epoch =  669 Batch =  0 Loss =  21.713462763516205 Gradient_max =  0.21419062260253152 learning rate ratio =  5.797171564476409e-07\n",
      "Epoch =  670 Batch =  0 Loss =  21.709353106723103 Gradient_max =  0.21413343990579192 learning rate ratio =  5.782422640909718e-07\n",
      "Epoch =  671 Batch =  0 Loss =  21.705269538415475 Gradient_max =  0.21407642425986073 learning rate ratio =  5.76775080435533e-07\n",
      "Epoch =  672 Batch =  0 Loss =  21.70121190148073 Gradient_max =  0.21401957469439586 learning rate ratio =  5.753155667875878e-07\n",
      "Epoch =  673 Batch =  0 Loss =  21.69718003982707 Gradient_max =  0.21396289024335186 learning rate ratio =  5.738636450935227e-07\n",
      "Epoch =  674 Batch =  0 Loss =  21.693173797763052 Gradient_max =  0.21390636994518447 learning rate ratio =  5.724193149616899e-07\n",
      "Epoch =  675 Batch =  0 Loss =  21.689193020955233 Gradient_max =  0.21385001284571745 learning rate ratio =  5.709825395193121e-07\n",
      "Epoch =  676 Batch =  0 Loss =  21.685237556074966 Gradient_max =  0.21379381799673744 learning rate ratio =  5.6955328047908e-07\n",
      "Epoch =  677 Batch =  0 Loss =  21.681307250770658 Gradient_max =  0.21373778445587466 learning rate ratio =  5.681314997126976e-07\n",
      "Epoch =  678 Batch =  0 Loss =  21.67740195366084 Gradient_max =  0.2136819112865636 learning rate ratio =  5.667171592689955e-07\n",
      "Epoch =  679 Batch =  0 Loss =  21.673521514327582 Gradient_max =  0.2136261975580075 learning rate ratio =  5.653102213735336e-07\n",
      "Epoch =  680 Batch =  0 Loss =  21.66966578377198 Gradient_max =  0.2135706423479646 learning rate ratio =  5.639106484194898e-07\n",
      "Epoch =  681 Batch =  0 Loss =  21.66583461410447 Gradient_max =  0.21351524474150338 learning rate ratio =  5.625184029775217e-07\n",
      "Epoch =  682 Batch =  0 Loss =  21.662027857008777 Gradient_max =  0.21346000382050306 learning rate ratio =  5.61133447814635e-07\n",
      "Epoch =  683 Batch =  0 Loss =  21.658245365495173 Gradient_max =  0.21340491867381448 learning rate ratio =  5.597557458574782e-07\n",
      "Epoch =  684 Batch =  0 Loss =  21.654486993862132 Gradient_max =  0.21334998839889455 learning rate ratio =  5.583852602058947e-07\n",
      "Epoch =  685 Batch =  0 Loss =  21.650752597337352 Gradient_max =  0.2132952120987839 learning rate ratio =  5.570219541327049e-07\n",
      "Epoch =  686 Batch =  0 Loss =  21.647042032067194 Gradient_max =  0.21324058888203654 learning rate ratio =  5.556657910830873e-07\n",
      "Epoch =  687 Batch =  0 Loss =  21.64335515511046 Gradient_max =  0.21318611786268438 learning rate ratio =  5.54316734673949e-07\n",
      "Epoch =  688 Batch =  0 Loss =  21.639691824740986 Gradient_max =  0.21313179816163141 learning rate ratio =  5.529747486908002e-07\n",
      "Epoch =  689 Batch =  0 Loss =  21.63605189958476 Gradient_max =  0.2130776289027606 learning rate ratio =  5.516397970942673e-07\n",
      "Epoch =  690 Batch =  0 Loss =  21.63243523982845 Gradient_max =  0.21302360922024005 learning rate ratio =  5.50311844013021e-07\n",
      "Epoch =  691 Batch =  0 Loss =  21.628841705652672 Gradient_max =  0.21296973824559667 learning rate ratio =  5.489908537445983e-07\n",
      "Epoch =  692 Batch =  0 Loss =  21.625271158540027 Gradient_max =  0.21291601511932226 learning rate ratio =  5.476767907551668e-07\n",
      "Epoch =  693 Batch =  0 Loss =  21.621723460895414 Gradient_max =  0.2128624389875806 learning rate ratio =  5.463696196788707e-07\n",
      "Epoch =  694 Batch =  0 Loss =  21.618198475994426 Gradient_max =  0.21280900900177663 learning rate ratio =  5.450693053172015e-07\n",
      "Epoch =  695 Batch =  0 Loss =  21.614696067976897 Gradient_max =  0.21275572431851794 learning rate ratio =  5.437758126383715e-07\n",
      "Epoch =  696 Batch =  0 Loss =  21.611216101841134 Gradient_max =  0.21270258409958132 learning rate ratio =  5.424891067766896e-07\n",
      "Epoch =  697 Batch =  0 Loss =  21.60775844343806 Gradient_max =  0.21264958751187993 learning rate ratio =  5.412091530319345e-07\n",
      "Epoch =  698 Batch =  0 Loss =  21.604322960168695 Gradient_max =  0.2125967337303198 learning rate ratio =  5.399358637097413e-07\n",
      "Epoch =  699 Batch =  0 Loss =  21.60090951886636 Gradient_max =  0.21254402192908417 learning rate ratio =  5.386692579171913e-07\n",
      "Epoch =  700 Batch =  0 Loss =  21.597517988004643 Gradient_max =  0.212491451290773 learning rate ratio =  5.374093019649881e-07\n",
      "Epoch =  701 Batch =  0 Loss =  21.594148236967545 Gradient_max =  0.21243902100446874 learning rate ratio =  5.361559618051345e-07\n",
      "Epoch =  702 Batch =  0 Loss =  21.590800135506814 Gradient_max =  0.21238673025990318 learning rate ratio =  5.34909203545146e-07\n",
      "Epoch =  703 Batch =  0 Loss =  21.587473564868112 Gradient_max =  0.2123345783602948 learning rate ratio =  5.336689934543051e-07\n",
      "Epoch =  704 Batch =  0 Loss =  21.584168402020566 Gradient_max =  0.21228256456130998 learning rate ratio =  5.324352979630809e-07\n",
      "Epoch =  705 Batch =  0 Loss =  21.58088450331481 Gradient_max =  0.21223068790573446 learning rate ratio =  5.312080836625194e-07\n",
      "Epoch =  706 Batch =  0 Loss =  21.577621742022988 Gradient_max =  0.2121789476052646 learning rate ratio =  5.29987317303679e-07\n",
      "Epoch =  707 Batch =  0 Loss =  21.574379992218812 Gradient_max =  0.21212734287644927 learning rate ratio =  5.287729657969632e-07\n",
      "Epoch =  708 Batch =  0 Loss =  21.57115912876774 Gradient_max =  0.21207587294062466 learning rate ratio =  5.27564996211497e-07\n",
      "Epoch =  709 Batch =  0 Loss =  21.567959027321677 Gradient_max =  0.21202453702388163 learning rate ratio =  5.263633757745069e-07\n",
      "Epoch =  710 Batch =  0 Loss =  21.564779564313667 Gradient_max =  0.21197333435703497 learning rate ratio =  5.25168071870698e-07\n",
      "Epoch =  711 Batch =  0 Loss =  21.561620617052125 Gradient_max =  0.21192226417641 learning rate ratio =  5.239790520416338e-07\n",
      "Epoch =  712 Batch =  0 Loss =  21.5584820634264 Gradient_max =  0.2118713257214356 learning rate ratio =  5.22796283985099e-07\n",
      "Epoch =  713 Batch =  0 Loss =  21.555363782171195 Gradient_max =  0.2118205182368328 learning rate ratio =  5.216197355545164e-07\n",
      "Epoch =  714 Batch =  0 Loss =  21.552265652792318 Gradient_max =  0.21176984097201348 learning rate ratio =  5.204493747583141e-07\n",
      "Epoch =  715 Batch =  0 Loss =  21.549187555605865 Gradient_max =  0.21171929318141663 learning rate ratio =  5.192851697593035e-07\n",
      "Epoch =  716 Batch =  0 Loss =  21.54612937168482 Gradient_max =  0.21166887412407911 learning rate ratio =  5.181270888740433e-07\n",
      "Epoch =  717 Batch =  0 Loss =  21.543090982885197 Gradient_max =  0.21161858306381512 learning rate ratio =  5.169751005722271e-07\n",
      "Epoch =  718 Batch =  0 Loss =  21.540072271522444 Gradient_max =  0.21156841926671194 learning rate ratio =  5.158291734761091e-07\n",
      "Epoch =  719 Batch =  0 Loss =  21.537073121167293 Gradient_max =  0.21151838200617484 learning rate ratio =  5.146892763573425e-07\n",
      "Epoch =  720 Batch =  0 Loss =  21.534093415412045 Gradient_max =  0.2114684705569394 learning rate ratio =  5.135553781439084e-07\n",
      "Epoch =  721 Batch =  0 Loss =  21.53113303893467 Gradient_max =  0.21141868419978982 learning rate ratio =  5.124274479120882e-07\n",
      "Epoch =  722 Batch =  0 Loss =  21.528191877145833 Gradient_max =  0.21136902221993964 learning rate ratio =  5.113054548881726e-07\n",
      "Epoch =  723 Batch =  0 Loss =  21.525269816234626 Gradient_max =  0.2113194839074582 learning rate ratio =  5.101893684479203e-07\n",
      "Epoch =  724 Batch =  0 Loss =  21.52236674298299 Gradient_max =  0.21127006855576314 learning rate ratio =  5.090791581159554e-07\n",
      "Epoch =  725 Batch =  0 Loss =  21.51948254496883 Gradient_max =  0.21122077546320847 learning rate ratio =  5.079747935651642e-07\n",
      "Epoch =  726 Batch =  0 Loss =  21.516617110399675 Gradient_max =  0.21117160393199802 learning rate ratio =  5.06876244616081e-07\n",
      "Epoch =  727 Batch =  0 Loss =  21.513770328413752 Gradient_max =  0.21112255327042917 learning rate ratio =  5.057834812362704e-07\n",
      "Epoch =  728 Batch =  0 Loss =  21.510942088683716 Gradient_max =  0.21107362278893216 learning rate ratio =  5.046964735384462e-07\n",
      "Epoch =  729 Batch =  0 Loss =  21.508132281312275 Gradient_max =  0.2110248118014296 learning rate ratio =  5.036151917836737e-07\n",
      "Epoch =  730 Batch =  0 Loss =  21.50534079729476 Gradient_max =  0.21097611962708845 learning rate ratio =  5.02539606377126e-07\n",
      "Epoch =  731 Batch =  0 Loss =  21.502567528559698 Gradient_max =  0.21092754559127744 learning rate ratio =  5.014696878685025e-07\n",
      "Epoch =  732 Batch =  0 Loss =  21.499812367434814 Gradient_max =  0.2108790890211737 learning rate ratio =  5.004054069515042e-07\n",
      "Epoch =  733 Batch =  0 Loss =  21.497075206744935 Gradient_max =  0.210830749246579 learning rate ratio =  4.993467344632918e-07\n",
      "Epoch =  734 Batch =  0 Loss =  21.494355940185017 Gradient_max =  0.21078252560306132 learning rate ratio =  4.982936413838668e-07\n",
      "Epoch =  735 Batch =  0 Loss =  21.491654462115534 Gradient_max =  0.2107344174302509 learning rate ratio =  4.972460988354618e-07\n",
      "Epoch =  736 Batch =  0 Loss =  21.48897066773097 Gradient_max =  0.21068642407326035 learning rate ratio =  4.962040780819225e-07\n",
      "Epoch =  737 Batch =  0 Loss =  21.486304452523854 Gradient_max =  0.21063854487821185 learning rate ratio =  4.951675505281517e-07\n",
      "Epoch =  738 Batch =  0 Loss =  21.48365571283507 Gradient_max =  0.2105907791967872 learning rate ratio =  4.941364877195026e-07\n",
      "Epoch =  739 Batch =  0 Loss =  21.481024345606617 Gradient_max =  0.21054312638435616 learning rate ratio =  4.93110861341178e-07\n",
      "Epoch =  740 Batch =  0 Loss =  21.47841024862797 Gradient_max =  0.21049558580114847 learning rate ratio =  4.920906432164161e-07\n",
      "Epoch =  741 Batch =  0 Loss =  21.475813319947942 Gradient_max =  0.21044815680957082 learning rate ratio =  4.910758053095671e-07\n",
      "Epoch =  742 Batch =  0 Loss =  21.473233458961722 Gradient_max =  0.21040083877878682 learning rate ratio =  4.900662542872261e-07\n",
      "Epoch =  743 Batch =  0 Loss =  21.470670564838937 Gradient_max =  0.21035363107901178 learning rate ratio =  4.890620275075538e-07\n",
      "Epoch =  744 Batch =  0 Loss =  21.46812453758638 Gradient_max =  0.21030653308443678 learning rate ratio =  4.880630986522124e-07\n",
      "Epoch =  745 Batch =  0 Loss =  21.46559527789028 Gradient_max =  0.2102595441729356 learning rate ratio =  4.870694286918817e-07\n",
      "Epoch =  746 Batch =  0 Loss =  21.463082687477108 Gradient_max =  0.21021266372820288 learning rate ratio =  4.860809835799853e-07\n",
      "Epoch =  747 Batch =  0 Loss =  21.460586667890286 Gradient_max =  0.2101658911346538 learning rate ratio =  4.850977545503249e-07\n",
      "Epoch =  748 Batch =  0 Loss =  21.458107121697964 Gradient_max =  0.2101192257820003 learning rate ratio =  4.841197147232338e-07\n",
      "Epoch =  749 Batch =  0 Loss =  21.455643952076382 Gradient_max =  0.21007266706365837 learning rate ratio =  4.831468371361345e-07\n",
      "Epoch =  750 Batch =  0 Loss =  21.45319706282801 Gradient_max =  0.21002621437686617 learning rate ratio =  4.821790949574627e-07\n",
      "Epoch =  751 Batch =  0 Loss =  21.450766358298 Gradient_max =  0.20997986712219102 learning rate ratio =  4.812164614886422e-07\n",
      "Epoch =  752 Batch =  0 Loss =  21.4483517435021 Gradient_max =  0.20993362470428262 learning rate ratio =  4.802589101635414e-07\n",
      "Epoch =  753 Batch =  0 Loss =  21.44595312394014 Gradient_max =  0.20988748653077594 learning rate ratio =  4.793064145478911e-07\n",
      "Epoch =  754 Batch =  0 Loss =  21.44357040573795 Gradient_max =  0.20984145201312554 learning rate ratio =  4.783589483387227e-07\n",
      "Epoch =  755 Batch =  0 Loss =  21.441203495608427 Gradient_max =  0.20979552056637701 learning rate ratio =  4.774164853637902e-07\n",
      "Epoch =  756 Batch =  0 Loss =  21.438852300840573 Gradient_max =  0.20974969160910245 learning rate ratio =  4.7647899958099886e-07\n",
      "Epoch =  757 Batch =  0 Loss =  21.436516729388227 Gradient_max =  0.20970396456379628 learning rate ratio =  4.755464650773036e-07\n",
      "Epoch =  758 Batch =  0 Loss =  21.434196689635844 Gradient_max =  0.20965833885580806 learning rate ratio =  4.7461885606945917e-07\n",
      "Epoch =  759 Batch =  0 Loss =  21.43189209052925 Gradient_max =  0.20961281391393305 learning rate ratio =  4.7369614690268895e-07\n",
      "Epoch =  760 Batch =  0 Loss =  21.42960284162382 Gradient_max =  0.20956738917062356 learning rate ratio =  4.7277831204982655e-07\n",
      "Epoch =  761 Batch =  0 Loss =  21.427328853099283 Gradient_max =  0.2095220640622831 learning rate ratio =  4.718653261110113e-07\n",
      "Epoch =  762 Batch =  0 Loss =  21.425070035558697 Gradient_max =  0.20947683802765835 learning rate ratio =  4.7095716381314703e-07\n",
      "Epoch =  763 Batch =  0 Loss =  21.422826300216727 Gradient_max =  0.20943171050936485 learning rate ratio =  4.7005380000933814e-07\n",
      "Epoch =  764 Batch =  0 Loss =  21.4205975588378 Gradient_max =  0.20938668095339436 learning rate ratio =  4.69155209678328e-07\n",
      "Epoch =  765 Batch =  0 Loss =  21.418383723748192 Gradient_max =  0.2093417488092192 learning rate ratio =  4.682613679239394e-07\n",
      "Epoch =  766 Batch =  0 Loss =  21.41618470786126 Gradient_max =  0.20929691352970145 learning rate ratio =  4.673722182857219e-07\n",
      "Epoch =  767 Batch =  0 Loss =  21.414000424772475 Gradient_max =  0.2092521745715099 learning rate ratio =  4.6648772711071277e-07\n",
      "Epoch =  768 Batch =  0 Loss =  21.4118307880986 Gradient_max =  0.20920753139269999 learning rate ratio =  4.656079111870716e-07\n",
      "Epoch =  769 Batch =  0 Loss =  21.40967571242528 Gradient_max =  0.20916298345633624 learning rate ratio =  4.647327465910374e-07\n",
      "Epoch =  770 Batch =  0 Loss =  21.40753511260588 Gradient_max =  0.20911853022756516 learning rate ratio =  4.6386220903704556e-07\n",
      "Epoch =  771 Batch =  0 Loss =  21.405408904105713 Gradient_max =  0.20907417117513816 learning rate ratio =  4.629962743551528e-07\n",
      "Epoch =  772 Batch =  0 Loss =  21.403297002937133 Gradient_max =  0.20902990577111927 learning rate ratio =  4.621349184965534e-07\n",
      "Epoch =  773 Batch =  0 Loss =  21.40119932562853 Gradient_max =  0.20898573349074112 learning rate ratio =  4.6127811753325664e-07\n",
      "Epoch =  774 Batch =  0 Loss =  21.399115789220613 Gradient_max =  0.20894165381238491 learning rate ratio =  4.604258476575478e-07\n",
      "Epoch =  775 Batch =  0 Loss =  21.3970463112631 Gradient_max =  0.2088976662175599 learning rate ratio =  4.5957808518144396e-07\n",
      "Epoch =  776 Batch =  0 Loss =  21.394990809811453 Gradient_max =  0.2088537701908844 learning rate ratio =  4.58734806536156e-07\n",
      "Epoch =  777 Batch =  0 Loss =  21.392949203438977 Gradient_max =  0.2088099652201509 learning rate ratio =  4.5789598827154425e-07\n",
      "Epoch =  778 Batch =  0 Loss =  21.390921411241127 Gradient_max =  0.20876625079629998 learning rate ratio =  4.570616070553512e-07\n",
      "Epoch =  779 Batch =  0 Loss =  21.388907352840455 Gradient_max =  0.20872262641391193 learning rate ratio =  4.5623163967335484e-07\n",
      "Epoch =  780 Batch =  0 Loss =  21.38690694815956 Gradient_max =  0.2086790915688458 learning rate ratio =  4.5540606302816087e-07\n",
      "Epoch =  781 Batch =  0 Loss =  21.384920117730957 Gradient_max =  0.2086356457609493 learning rate ratio =  4.545848541388902e-07\n",
      "Epoch =  782 Batch =  0 Loss =  21.3829467829385 Gradient_max =  0.20859228849445627 learning rate ratio =  4.5376794339772207e-07\n",
      "Epoch =  783 Batch =  0 Loss =  21.380986864981413 Gradient_max =  0.20854901927405137 learning rate ratio =  4.5295535046991394e-07\n",
      "Epoch =  784 Batch =  0 Loss =  21.379040285783784 Gradient_max =  0.20850583760830135 learning rate ratio =  4.5214705780060453e-07\n",
      "Epoch =  785 Batch =  0 Loss =  21.37710696786627 Gradient_max =  0.20846274300920303 learning rate ratio =  4.5134304291993e-07\n",
      "Epoch =  786 Batch =  0 Loss =  21.37518683432719 Gradient_max =  0.20841973499199892 learning rate ratio =  4.505432659709977e-07\n",
      "Epoch =  787 Batch =  0 Loss =  21.373279808771457 Gradient_max =  0.20837681307496497 learning rate ratio =  4.497477093194866e-07\n",
      "Epoch =  788 Batch =  0 Loss =  21.371385814652438 Gradient_max =  0.20833397677695467 learning rate ratio =  4.4895636385784485e-07\n",
      "Epoch =  789 Batch =  0 Loss =  21.369504776306275 Gradient_max =  0.20829122562125874 learning rate ratio =  4.481692076588656e-07\n",
      "Epoch =  790 Batch =  0 Loss =  21.367636618635807 Gradient_max =  0.20824855913484 learning rate ratio =  4.473862187535481e-07\n",
      "Epoch =  791 Batch =  0 Loss =  21.365781266875118 Gradient_max =  0.2082059768464589 learning rate ratio =  4.4660737528251445e-07\n",
      "Epoch =  792 Batch =  0 Loss =  21.36393864670271 Gradient_max =  0.20816347828759094 learning rate ratio =  4.4583265549730544e-07\n",
      "Epoch =  793 Batch =  0 Loss =  21.362108684294878 Gradient_max =  0.20812106299277044 learning rate ratio =  4.4506203775988736e-07\n",
      "Epoch =  794 Batch =  0 Loss =  21.36029130623969 Gradient_max =  0.20807873049917916 learning rate ratio =  4.4429550054213826e-07\n",
      "Epoch =  795 Batch =  0 Loss =  21.358486439599506 Gradient_max =  0.20803648034691163 learning rate ratio =  4.4353302242534067e-07\n",
      "Epoch =  796 Batch =  0 Loss =  21.356694011888045 Gradient_max =  0.20799431207884422 learning rate ratio =  4.4277458209967014e-07\n",
      "Epoch =  797 Batch =  0 Loss =  21.354913951060816 Gradient_max =  0.2079522252405804 learning rate ratio =  4.4202015836368977e-07\n",
      "Epoch =  798 Batch =  0 Loss =  21.35314618560975 Gradient_max =  0.20791021938099594 learning rate ratio =  4.4126973012289644e-07\n",
      "Epoch =  799 Batch =  0 Loss =  21.351390644303912 Gradient_max =  0.20786829405074086 learning rate ratio =  4.405232763917174e-07\n",
      "Epoch =  800 Batch =  0 Loss =  21.34964725636911 Gradient_max =  0.20782644880327603 learning rate ratio =  4.397807762912222e-07\n",
      "Epoch =  801 Batch =  0 Loss =  21.34791595175553 Gradient_max =  0.20778468319685747 learning rate ratio =  4.3904220904791757e-07\n",
      "Epoch =  802 Batch =  0 Loss =  21.346196660406523 Gradient_max =  0.20774299678906863 learning rate ratio =  4.3830755399490603e-07\n",
      "Epoch =  803 Batch =  0 Loss =  21.344489312786912 Gradient_max =  0.20770138914095748 learning rate ratio =  4.375767905709605e-07\n",
      "Epoch =  804 Batch =  0 Loss =  21.34279383986516 Gradient_max =  0.2076598598167372 learning rate ratio =  4.3684989831932676e-07\n",
      "Epoch =  805 Batch =  0 Loss =  21.34111017309841 Gradient_max =  0.20761840838376341 learning rate ratio =  4.361268568876442e-07\n",
      "Epoch =  806 Batch =  0 Loss =  21.33943824438395 Gradient_max =  0.2075770344121558 learning rate ratio =  4.354076460274447e-07\n",
      "Epoch =  807 Batch =  0 Loss =  21.33777798578097 Gradient_max =  0.20753573747257564 learning rate ratio =  4.34692245593688e-07\n",
      "Epoch =  808 Batch =  0 Loss =  21.336129329919615 Gradient_max =  0.20749451713950626 learning rate ratio =  4.3398063554427854e-07\n",
      "Epoch =  809 Batch =  0 Loss =  21.334492209935807 Gradient_max =  0.20745337299073047 learning rate ratio =  4.332727959395689e-07\n",
      "Epoch =  810 Batch =  0 Loss =  21.33286655920837 Gradient_max =  0.20741230460524354 learning rate ratio =  4.3256870694186615e-07\n",
      "Epoch =  811 Batch =  0 Loss =  21.331252311560934 Gradient_max =  0.20737131156486602 learning rate ratio =  4.3186834881496905e-07\n",
      "Epoch =  812 Batch =  0 Loss =  21.329649401245906 Gradient_max =  0.20733039345412196 learning rate ratio =  4.3117170192368376e-07\n",
      "Epoch =  813 Batch =  0 Loss =  21.32805776291473 Gradient_max =  0.20728954986000445 learning rate ratio =  4.304787467333421e-07\n",
      "Epoch =  814 Batch =  0 Loss =  21.326477331671196 Gradient_max =  0.20724878037227049 learning rate ratio =  4.2978946380932447e-07\n",
      "Epoch =  815 Batch =  0 Loss =  21.324908043059924 Gradient_max =  0.20720808458365117 learning rate ratio =  4.2910383381599954e-07\n",
      "Epoch =  816 Batch =  0 Loss =  21.323349832795436 Gradient_max =  0.20716746208758477 learning rate ratio =  4.2842183751774493e-07\n",
      "Epoch =  817 Batch =  0 Loss =  21.32180263705409 Gradient_max =  0.2071269124804687 learning rate ratio =  4.27743455777508e-07\n",
      "Epoch =  818 Batch =  0 Loss =  21.320266392623164 Gradient_max =  0.2070864353620848 learning rate ratio =  4.2706863573899977e-07\n",
      "Epoch =  819 Batch =  0 Loss =  21.31874103631369 Gradient_max =  0.20704603033324093 learning rate ratio =  4.263973924850041e-07\n",
      "Epoch =  820 Batch =  0 Loss =  21.31722650549581 Gradient_max =  0.20700569699777674 learning rate ratio =  4.2572970748476546e-07\n",
      "Epoch =  821 Batch =  0 Loss =  21.315722737921263 Gradient_max =  0.2069654349618908 learning rate ratio =  4.2506556198829986e-07\n",
      "Epoch =  822 Batch =  0 Loss =  21.314229671718387 Gradient_max =  0.2069252438341162 learning rate ratio =  4.2440493733823844e-07\n",
      "Epoch =  823 Batch =  0 Loss =  21.31274724538968 Gradient_max =  0.20688512322530558 learning rate ratio =  4.2374781497307984e-07\n",
      "Epoch =  824 Batch =  0 Loss =  21.311275397809467 Gradient_max =  0.20684507274861785 learning rate ratio =  4.230941764267749e-07\n",
      "Epoch =  825 Batch =  0 Loss =  21.309814068322915 Gradient_max =  0.20680509201995076 learning rate ratio =  4.22444003327928e-07\n",
      "Epoch =  826 Batch =  0 Loss =  21.30836319650758 Gradient_max =  0.2067651806571026 learning rate ratio =  4.2179727740033594e-07\n",
      "Epoch =  827 Batch =  0 Loss =  21.30692272227315 Gradient_max =  0.20672533827956416 learning rate ratio =  4.21153980461589e-07\n",
      "Epoch =  828 Batch =  0 Loss =  21.305492586063803 Gradient_max =  0.20668556451040507 learning rate ratio =  4.2051409442288244e-07\n",
      "Epoch =  829 Batch =  0 Loss =  21.304072728521643 Gradient_max =  0.20664585897365612 learning rate ratio =  4.1987760128859345e-07\n",
      "Epoch =  830 Batch =  0 Loss =  21.302663090646647 Gradient_max =  0.20660622129557174 learning rate ratio =  4.1924448315584315e-07\n",
      "Epoch =  831 Batch =  0 Loss =  21.301263613850292 Gradient_max =  0.20656665110505396 learning rate ratio =  4.1861472221404125e-07\n",
      "Epoch =  832 Batch =  0 Loss =  21.29987423989816 Gradient_max =  0.20652714803320377 learning rate ratio =  4.1798830074444056e-07\n",
      "Epoch =  833 Batch =  0 Loss =  21.298494910907078 Gradient_max =  0.20648771171330366 learning rate ratio =  4.173652011196924e-07\n",
      "Epoch =  834 Batch =  0 Loss =  21.297125569342864 Gradient_max =  0.20644834178080368 learning rate ratio =  4.1674540580340543e-07\n",
      "Epoch =  835 Batch =  0 Loss =  21.295766158018157 Gradient_max =  0.20640903787330855 learning rate ratio =  4.161288973497062e-07\n",
      "Epoch =  836 Batch =  0 Loss =  21.29441662009021 Gradient_max =  0.2063697996305641 learning rate ratio =  4.155156584028009e-07\n",
      "Epoch =  837 Batch =  0 Loss =  21.293076899058747 Gradient_max =  0.20633062669444444 learning rate ratio =  4.149056716965384e-07\n",
      "Epoch =  838 Batch =  0 Loss =  21.291746938820243 Gradient_max =  0.20629151870937767 learning rate ratio =  4.142989200539738e-07\n",
      "Epoch =  839 Batch =  0 Loss =  21.290426683508137 Gradient_max =  0.2062524753211048 learning rate ratio =  4.136953863869355e-07\n",
      "Epoch =  840 Batch =  0 Loss =  21.289116077623998 Gradient_max =  0.20621349617770723 learning rate ratio =  4.130950536956014e-07\n",
      "Epoch =  841 Batch =  0 Loss =  21.287815066071584 Gradient_max =  0.20617458092987767 learning rate ratio =  4.1249790506806327e-07\n",
      "Epoch =  842 Batch =  0 Loss =  21.28652359397696 Gradient_max =  0.2061357292295123 learning rate ratio =  4.119039236798976e-07\n",
      "Epoch =  843 Batch =  0 Loss =  21.285241606847162 Gradient_max =  0.20609694073096174 learning rate ratio =  4.1131309279374805e-07\n",
      "Epoch =  844 Batch =  0 Loss =  21.283969050519623 Gradient_max =  0.20605821509063602 learning rate ratio =  4.10725395758896e-07\n",
      "Epoch =  845 Batch =  0 Loss =  21.28270587116664 Gradient_max =  0.2060195519670194 learning rate ratio =  4.1014081601069457e-07\n",
      "Epoch =  846 Batch =  0 Loss =  21.281452015273818 Gradient_max =  0.2059809510205565 learning rate ratio =  4.095593370704537e-07\n",
      "Epoch =  847 Batch =  0 Loss =  21.280207429641028 Gradient_max =  0.20594241191365462 learning rate ratio =  4.0898094254497065e-07\n",
      "Epoch =  848 Batch =  0 Loss =  21.278972061395937 Gradient_max =  0.20590393431075266 learning rate ratio =  4.0840561612587314e-07\n",
      "Epoch =  849 Batch =  0 Loss =  21.277745857983845 Gradient_max =  0.2058655178782683 learning rate ratio =  4.078333415893302e-07\n",
      "Epoch =  850 Batch =  0 Loss =  21.2765287672284 Gradient_max =  0.20582716228502934 learning rate ratio =  4.0726410279559477e-07\n",
      "Epoch =  851 Batch =  0 Loss =  21.275320737248233 Gradient_max =  0.20578886720140696 learning rate ratio =  4.0669788368836457e-07\n",
      "Epoch =  852 Batch =  0 Loss =  21.274121716321076 Gradient_max =  0.20575063229918408 learning rate ratio =  4.061346682953119e-07\n",
      "Epoch =  853 Batch =  0 Loss =  21.272931653141402 Gradient_max =  0.20571245725256004 learning rate ratio =  4.0557444072666185e-07\n",
      "Epoch =  854 Batch =  0 Loss =  21.27175049671269 Gradient_max =  0.20567434173765692 learning rate ratio =  4.050171851751271e-07\n",
      "Epoch =  855 Batch =  0 Loss =  21.270578196344257 Gradient_max =  0.20563628543250248 learning rate ratio =  4.044628859155063e-07\n",
      "Epoch =  856 Batch =  0 Loss =  21.269414701673163 Gradient_max =  0.2055982880171227 learning rate ratio =  4.0391152730421644e-07\n",
      "Epoch =  857 Batch =  0 Loss =  21.268259962592925 Gradient_max =  0.2055603491732265 learning rate ratio =  4.0336309377907616e-07\n",
      "Epoch =  858 Batch =  0 Loss =  21.267113929316302 Gradient_max =  0.2055224685844779 learning rate ratio =  4.028175698587348e-07\n",
      "Epoch =  859 Batch =  0 Loss =  21.265976552375975 Gradient_max =  0.2054846459364955 learning rate ratio =  4.022749401422654e-07\n",
      "Epoch =  860 Batch =  0 Loss =  21.26484778256476 Gradient_max =  0.2054468809165861 learning rate ratio =  4.0173518930892315e-07\n",
      "Epoch =  861 Batch =  0 Loss =  21.263727571039414 Gradient_max =  0.20540917321418778 learning rate ratio =  4.011983021174493e-07\n",
      "Epoch =  862 Batch =  0 Loss =  21.26261586915761 Gradient_max =  0.20537152252017982 learning rate ratio =  4.00664263406157e-07\n",
      "Epoch =  863 Batch =  0 Loss =  21.26151262859146 Gradient_max =  0.20533392852735516 learning rate ratio =  4.0013305809219567e-07\n",
      "Epoch =  864 Batch =  0 Loss =  21.260417801317963 Gradient_max =  0.20529639093037724 learning rate ratio =  3.9960467117118357e-07\n",
      "Epoch =  865 Batch =  0 Loss =  21.259331339601527 Gradient_max =  0.20525890942570255 learning rate ratio =  3.990790877168646e-07\n",
      "Epoch =  866 Batch =  0 Loss =  21.258253196046965 Gradient_max =  0.20522148371179927 learning rate ratio =  3.985562928805555e-07\n",
      "Epoch =  867 Batch =  0 Loss =  21.257183323433143 Gradient_max =  0.2051841134884464 learning rate ratio =  3.9803627189125803e-07\n",
      "Epoch =  868 Batch =  0 Loss =  21.2561216748746 Gradient_max =  0.20514679845740996 learning rate ratio =  3.9751901005478544e-07\n",
      "Epoch =  869 Batch =  0 Loss =  21.25506820376708 Gradient_max =  0.20510953832220866 learning rate ratio =  3.9700449275353767e-07\n",
      "Epoch =  870 Batch =  0 Loss =  21.25402286380381 Gradient_max =  0.20507233278820086 learning rate ratio =  3.964927054461229e-07\n",
      "Epoch =  871 Batch =  0 Loss =  21.252985608920095 Gradient_max =  0.20503518156228998 learning rate ratio =  3.959836336669801e-07\n",
      "Epoch =  872 Batch =  0 Loss =  21.251956393338062 Gradient_max =  0.20499808435315964 learning rate ratio =  3.95477263026004e-07\n",
      "Epoch =  873 Batch =  0 Loss =  21.250935171556854 Gradient_max =  0.2049610408712205 learning rate ratio =  3.9497357920816746e-07\n",
      "Epoch =  874 Batch =  0 Loss =  21.24992189837448 Gradient_max =  0.20492405082869625 learning rate ratio =  3.944725679730745e-07\n",
      "Epoch =  875 Batch =  0 Loss =  21.248916528805285 Gradient_max =  0.20488711393926934 learning rate ratio =  3.939742151548078e-07\n",
      "Epoch =  876 Batch =  0 Loss =  21.247919018156853 Gradient_max =  0.20485022991840532 learning rate ratio =  3.934785066613456e-07\n",
      "Epoch =  877 Batch =  0 Loss =  21.24692932201297 Gradient_max =  0.2048133984832825 learning rate ratio =  3.929854284742571e-07\n",
      "Epoch =  878 Batch =  0 Loss =  21.245947396206073 Gradient_max =  0.20477661935265526 learning rate ratio =  3.924949666483376e-07\n",
      "Epoch =  879 Batch =  0 Loss =  21.244973196839393 Gradient_max =  0.20473989224696104 learning rate ratio =  3.9200710731124566e-07\n",
      "Epoch =  880 Batch =  0 Loss =  21.244006680278247 Gradient_max =  0.2047032168882761 learning rate ratio =  3.915218366631372e-07\n",
      "Epoch =  881 Batch =  0 Loss =  21.24304780318924 Gradient_max =  0.20466659300061296 learning rate ratio =  3.9103914097629996e-07\n",
      "Epoch =  882 Batch =  0 Loss =  21.24209652241569 Gradient_max =  0.2046300203089853 learning rate ratio =  3.9055900659479947e-07\n",
      "Epoch =  883 Batch =  0 Loss =  21.241152795096745 Gradient_max =  0.20459349854030712 learning rate ratio =  3.900814199341184e-07\n",
      "Epoch =  884 Batch =  0 Loss =  21.240216578628218 Gradient_max =  0.2045570274231011 learning rate ratio =  3.896063674807969e-07\n",
      "Epoch =  885 Batch =  0 Loss =  21.239287830659578 Gradient_max =  0.20452060668747696 learning rate ratio =  3.89133835792078e-07\n",
      "Epoch =  886 Batch =  0 Loss =  21.238366509092387 Gradient_max =  0.2044842360651226 learning rate ratio =  3.8866381149555244e-07\n",
      "Epoch =  887 Batch =  0 Loss =  21.237452572089982 Gradient_max =  0.20444791528937756 learning rate ratio =  3.881962812888053e-07\n",
      "Epoch =  888 Batch =  0 Loss =  21.23654597806542 Gradient_max =  0.20441164409512635 learning rate ratio =  3.8773123193906367e-07\n",
      "Epoch =  889 Batch =  0 Loss =  21.235646685644017 Gradient_max =  0.20437542221857657 learning rate ratio =  3.8726865028285064e-07\n",
      "Epoch =  890 Batch =  0 Loss =  21.234754653719556 Gradient_max =  0.2043392493976286 learning rate ratio =  3.868085232256368e-07\n",
      "Epoch =  891 Batch =  0 Loss =  21.233869841430828 Gradient_max =  0.20430312537171624 learning rate ratio =  3.8635083774149236e-07\n",
      "Epoch =  892 Batch =  0 Loss =  21.232992208159526 Gradient_max =  0.2042670498817952 learning rate ratio =  3.8589558087274256e-07\n",
      "Epoch =  893 Batch =  0 Loss =  21.23212171352873 Gradient_max =  0.20423102267033283 learning rate ratio =  3.854427397296236e-07\n",
      "Epoch =  894 Batch =  0 Loss =  21.231258317401405 Gradient_max =  0.20419504348129996 learning rate ratio =  3.8499230148994137e-07\n",
      "Epoch =  895 Batch =  0 Loss =  21.23040197987897 Gradient_max =  0.2041591120601608 learning rate ratio =  3.845442533987308e-07\n",
      "Epoch =  896 Batch =  0 Loss =  21.229552661299753 Gradient_max =  0.20412322815386552 learning rate ratio =  3.840985827679173e-07\n",
      "Epoch =  897 Batch =  0 Loss =  21.228710322237614 Gradient_max =  0.2040873915108395 learning rate ratio =  3.836552769759792e-07\n",
      "Epoch =  898 Batch =  0 Loss =  21.227874923521533 Gradient_max =  0.20405160188113375 learning rate ratio =  3.832143234676116e-07\n",
      "Epoch =  899 Batch =  0 Loss =  21.227046426184263 Gradient_max =  0.20401585901601424 learning rate ratio =  3.827757097533909e-07\n",
      "Epoch =  900 Batch =  0 Loss =  21.22622479152741 Gradient_max =  0.2039801626683661 learning rate ratio =  3.823394155570069e-07\n",
      "Epoch =  901 Batch =  0 Loss =  21.22540998100844 Gradient_max =  0.20394451259226778 learning rate ratio =  3.819054364408234e-07\n",
      "Epoch =  902 Batch =  0 Loss =  21.22460195635647 Gradient_max =  0.2039089085433905 learning rate ratio =  3.81473760167807e-07\n",
      "Epoch =  903 Batch =  0 Loss =  21.223800679544887 Gradient_max =  0.20387335027891593 learning rate ratio =  3.810443745078557e-07\n",
      "Epoch =  904 Batch =  0 Loss =  21.223006112739572 Gradient_max =  0.20383783755727253 learning rate ratio =  3.8061726729443724e-07\n",
      "Epoch =  905 Batch =  0 Loss =  21.22221821834624 Gradient_max =  0.2038023701383754 learning rate ratio =  3.801924264249394e-07\n",
      "Epoch =  906 Batch =  0 Loss =  21.221436958994033 Gradient_max =  0.20376694778354065 learning rate ratio =  3.7976983986035356e-07\n",
      "Epoch =  907 Batch =  0 Loss =  21.2206622975335 Gradient_max =  0.20373157025547456 learning rate ratio =  3.793494956249528e-07\n",
      "Epoch =  908 Batch =  0 Loss =  21.219894197035234 Gradient_max =  0.20369623731826308 learning rate ratio =  3.789313818059701e-07\n",
      "Epoch =  909 Batch =  0 Loss =  21.219132620788525 Gradient_max =  0.20366094873736657 learning rate ratio =  3.785154865532795e-07\n",
      "Epoch =  910 Batch =  0 Loss =  21.21837753230002 Gradient_max =  0.20362570427960913 learning rate ratio =  3.7810179807907777e-07\n",
      "Epoch =  911 Batch =  0 Loss =  21.21762889529238 Gradient_max =  0.20359050371317192 learning rate ratio =  3.77690304657568e-07\n",
      "Epoch =  912 Batch =  0 Loss =  21.21688667370297 Gradient_max =  0.2035553468075835 learning rate ratio =  3.772809946246446e-07\n",
      "Epoch =  913 Batch =  0 Loss =  21.216150831682526 Gradient_max =  0.203520233333714 learning rate ratio =  3.7687385637757915e-07\n",
      "Epoch =  914 Batch =  0 Loss =  21.21542133359387 Gradient_max =  0.20348516306376396 learning rate ratio =  3.7646887837470884e-07\n",
      "Epoch =  915 Batch =  0 Loss =  21.214698144010583 Gradient_max =  0.2034501357712595 learning rate ratio =  3.760660491351256e-07\n",
      "Epoch =  916 Batch =  0 Loss =  21.21398122771574 Gradient_max =  0.203415151231042 learning rate ratio =  3.756653572383663e-07\n",
      "Epoch =  917 Batch =  0 Loss =  21.2132705497006 Gradient_max =  0.2033802092192621 learning rate ratio =  3.752667913241053e-07\n",
      "Epoch =  918 Batch =  0 Loss =  21.212566075163377 Gradient_max =  0.20334530951336993 learning rate ratio =  3.748703400918482e-07\n",
      "Epoch =  919 Batch =  0 Loss =  21.21186776950791 Gradient_max =  0.20331045189210878 learning rate ratio =  3.744759923006264e-07\n",
      "Epoch =  920 Batch =  0 Loss =  21.211175598342468 Gradient_max =  0.20327563613550675 learning rate ratio =  3.740837367686937e-07\n",
      "Epoch =  921 Batch =  0 Loss =  21.210489527484025 Gradient_max =  0.20324086202490954 learning rate ratio =  3.7369356237322364e-07\n",
      "Epoch =  922 Batch =  0 Loss =  21.209809522950692 Gradient_max =  0.20320612934292703 learning rate ratio =  3.7330545805000865e-07\n",
      "Epoch =  923 Batch =  0 Loss =  21.209135550973578 Gradient_max =  0.20317143787342898 learning rate ratio =  3.729194127931043e-07\n",
      "Epoch =  924 Batch =  0 Loss =  21.20846757793919 Gradient_max =  0.20313678740139857 learning rate ratio =  3.7253541565470026e-07\n",
      "Epoch =  925 Batch =  0 Loss =  21.207805570458 Gradient_max =  0.20310217771316966 learning rate ratio =  3.7215345574466054e-07\n",
      "Epoch =  926 Batch =  0 Loss =  21.207149495338705 Gradient_max =  0.20306760859632011 learning rate ratio =  3.7177352223027646e-07\n",
      "Epoch =  927 Batch =  0 Loss =  21.206499319585827 Gradient_max =  0.20303307983965937 learning rate ratio =  3.713956043359767e-07\n",
      "Epoch =  928 Batch =  0 Loss =  21.2058550104329 Gradient_max =  0.20299859123341646 learning rate ratio =  3.710196913429963e-07\n",
      "Epoch =  929 Batch =  0 Loss =  21.205216535240627 Gradient_max =  0.20296414256866474 learning rate ratio =  3.7064577258919407e-07\n",
      "Epoch =  930 Batch =  0 Loss =  21.2045838615908 Gradient_max =  0.2029297336378461 learning rate ratio =  3.7027383746866035e-07\n",
      "Epoch =  931 Batch =  0 Loss =  21.203956957259315 Gradient_max =  0.20289536423462556 learning rate ratio =  3.6990387543146013e-07\n",
      "Epoch =  932 Batch =  0 Loss =  21.203335790212027 Gradient_max =  0.20286103415386317 learning rate ratio =  3.6953587598334583e-07\n",
      "Epoch =  933 Batch =  0 Loss =  21.202720328603537 Gradient_max =  0.20282674319160815 learning rate ratio =  3.6916982868547314e-07\n",
      "Epoch =  934 Batch =  0 Loss =  21.202110540776072 Gradient_max =  0.20279249114509074 learning rate ratio =  3.6880572315411603e-07\n",
      "Epoch =  935 Batch =  0 Loss =  21.201506395258324 Gradient_max =  0.20275827781271555 learning rate ratio =  3.6844354906038407e-07\n",
      "Epoch =  936 Batch =  0 Loss =  21.20090786076431 Gradient_max =  0.2027241029940547 learning rate ratio =  3.680832961299408e-07\n",
      "Epoch =  937 Batch =  0 Loss =  21.200314906192265 Gradient_max =  0.2026899664898413 learning rate ratio =  3.677249541427241e-07\n",
      "Epoch =  938 Batch =  0 Loss =  21.1997275006235 Gradient_max =  0.20265586810196043 learning rate ratio =  3.673685129326664e-07\n",
      "Epoch =  939 Batch =  0 Loss =  21.199145613321296 Gradient_max =  0.20262180763344456 learning rate ratio =  3.670139623874177e-07\n",
      "Epoch =  940 Batch =  0 Loss =  21.198569213729794 Gradient_max =  0.20258778488846657 learning rate ratio =  3.666612924480692e-07\n",
      "Epoch =  941 Batch =  0 Loss =  21.19799827147291 Gradient_max =  0.20255379967233092 learning rate ratio =  3.6631049310887866e-07\n",
      "Epoch =  942 Batch =  0 Loss =  21.1974327563532 Gradient_max =  0.2025198517914694 learning rate ratio =  3.6596155441699655e-07\n",
      "Epoch =  943 Batch =  0 Loss =  21.19687263835085 Gradient_max =  0.2024859410534323 learning rate ratio =  3.6561446647219334e-07\n",
      "Epoch =  944 Batch =  0 Loss =  21.19631788762252 Gradient_max =  0.2024520672668837 learning rate ratio =  3.6526921942658973e-07\n",
      "Epoch =  945 Batch =  0 Loss =  21.19576847450516 Gradient_max =  0.20241823024161687 learning rate ratio =  3.6492580348433926e-07\n",
      "Epoch =  946 Batch =  0 Loss =  21.1952243695072 Gradient_max =  0.20238442978850987 learning rate ratio =  3.645842089014354e-07\n",
      "Epoch =  947 Batch =  0 Loss =  21.1946855433015 Gradient_max =  0.20235066571949245 learning rate ratio =  3.642444259854999e-07\n",
      "Epoch =  948 Batch =  0 Loss =  21.194151966740012 Gradient_max =  0.20231693784761295 learning rate ratio =  3.6390644509536787e-07\n",
      "Epoch =  949 Batch =  0 Loss =  21.193623610845993 Gradient_max =  0.20228324598700098 learning rate ratio =  3.635702566408875e-07\n",
      "Epoch =  950 Batch =  0 Loss =  21.193100446824445 Gradient_max =  0.20224958995294046 learning rate ratio =  3.6323585108265723e-07\n",
      "Epoch =  951 Batch =  0 Loss =  21.19258244603004 Gradient_max =  0.20221596956164611 learning rate ratio =  3.629032189317635e-07\n",
      "Epoch =  952 Batch =  0 Loss =  21.19206957998958 Gradient_max =  0.2021823846304207 learning rate ratio =  3.625723507495212e-07\n",
      "Epoch =  953 Batch =  0 Loss =  21.1915618204113 Gradient_max =  0.20214883497770017 learning rate ratio =  3.622432371472139e-07\n",
      "Epoch =  954 Batch =  0 Loss =  21.19105913916218 Gradient_max =  0.2021153204229169 learning rate ratio =  3.6191586322614946e-07\n",
      "Epoch =  955 Batch =  0 Loss =  21.19056150827609 Gradient_max =  0.20208184078656322 learning rate ratio =  3.6159022373527284e-07\n",
      "Epoch =  956 Batch =  0 Loss =  21.19006889992706 Gradient_max =  0.2020483958900837 learning rate ratio =  3.6126631104892734e-07\n",
      "Epoch =  957 Batch =  0 Loss =  21.189581286470958 Gradient_max =  0.20201498555601896 learning rate ratio =  3.609441159934203e-07\n",
      "Epoch =  958 Batch =  0 Loss =  21.189098640426014 Gradient_max =  0.20198160960793435 learning rate ratio =  3.606236294248714e-07\n",
      "Epoch =  959 Batch =  0 Loss =  21.18862093447152 Gradient_max =  0.20194826787041287 learning rate ratio =  3.603048422476304e-07\n",
      "Epoch =  960 Batch =  0 Loss =  21.18814814145955 Gradient_max =  0.20191496016911423 learning rate ratio =  3.599877454141711e-07\n",
      "Epoch =  961 Batch =  0 Loss =  21.18768023437802 Gradient_max =  0.2018816863305845 learning rate ratio =  3.596723299250701e-07\n",
      "Epoch =  962 Batch =  0 Loss =  21.187217186413775 Gradient_max =  0.20184844618259395 learning rate ratio =  3.5935858682851555e-07\n",
      "Epoch =  963 Batch =  0 Loss =  21.18675897085219 Gradient_max =  0.2018152395535659 learning rate ratio =  3.59046507220182e-07\n",
      "Epoch =  964 Batch =  0 Loss =  21.1863055611598 Gradient_max =  0.20178206627306383 learning rate ratio =  3.5873608224294675e-07\n",
      "Epoch =  965 Batch =  0 Loss =  21.185856930973035 Gradient_max =  0.20174892617170687 learning rate ratio =  3.584273030865937e-07\n",
      "Epoch =  966 Batch =  0 Loss =  21.185413054063126 Gradient_max =  0.20171581908098743 learning rate ratio =  3.581201609877359e-07\n",
      "Epoch =  967 Batch =  0 Loss =  21.184973904361833 Gradient_max =  0.20168274483340343 learning rate ratio =  3.5781464722941434e-07\n",
      "Epoch =  968 Batch =  0 Loss =  21.184539459296225 Gradient_max =  0.20164970327090376 learning rate ratio =  3.5751075311344795e-07\n",
      "Epoch =  969 Batch =  0 Loss =  21.184109690612836 Gradient_max =  0.2016166942216529 learning rate ratio =  3.572084700360063e-07\n",
      "Epoch =  970 Batch =  0 Loss =  21.183684571802978 Gradient_max =  0.20158371751870893 learning rate ratio =  3.56907789425434e-07\n",
      "Epoch =  971 Batch =  0 Loss =  21.183264077405322 Gradient_max =  0.20155077299840532 learning rate ratio =  3.5660870274827247e-07\n",
      "Epoch =  972 Batch =  0 Loss =  21.182848182107577 Gradient_max =  0.2015178604980178 learning rate ratio =  3.5631120151634706e-07\n",
      "Epoch =  973 Batch =  0 Loss =  21.18243686076445 Gradient_max =  0.20148497985587543 learning rate ratio =  3.560152772864979e-07\n",
      "Epoch =  974 Batch =  0 Loss =  21.18203008835717 Gradient_max =  0.20145213091110714 learning rate ratio =  3.5572092166041567e-07\n",
      "Epoch =  975 Batch =  0 Loss =  21.181627839997663 Gradient_max =  0.20141931350367945 learning rate ratio =  3.5542812628439764e-07\n",
      "Epoch =  976 Batch =  0 Loss =  21.181230090959655 Gradient_max =  0.20138652747457644 learning rate ratio =  3.5513688284906255e-07\n",
      "Epoch =  977 Batch =  0 Loss =  21.18083681666205 Gradient_max =  0.20135377266570068 learning rate ratio =  3.548471830891464e-07\n",
      "Epoch =  978 Batch =  0 Loss =  21.180447992667364 Gradient_max =  0.20132104891986388 learning rate ratio =  3.545590187832726e-07\n",
      "Epoch =  979 Batch =  0 Loss =  21.180063594680835 Gradient_max =  0.20128835608078088 learning rate ratio =  3.542723817537251e-07\n",
      "Epoch =  980 Batch =  0 Loss =  21.179683598549595 Gradient_max =  0.20125569399306514 learning rate ratio =  3.539872638662187e-07\n",
      "Epoch =  981 Batch =  0 Loss =  21.17930798026178 Gradient_max =  0.20122306250222316 learning rate ratio =  3.5370365702967424e-07\n",
      "Epoch =  982 Batch =  0 Loss =  21.17893671594572 Gradient_max =  0.20119046145464858 learning rate ratio =  3.5342155319599286e-07\n",
      "Epoch =  983 Batch =  0 Loss =  21.178569781869058 Gradient_max =  0.20115789069761741 learning rate ratio =  3.5314094435983117e-07\n",
      "Epoch =  984 Batch =  0 Loss =  21.17820715443794 Gradient_max =  0.20112535007928348 learning rate ratio =  3.5286182255837936e-07\n",
      "Epoch =  985 Batch =  0 Loss =  21.17784881019798 Gradient_max =  0.20109283944868306 learning rate ratio =  3.52584179871138e-07\n",
      "Epoch =  986 Batch =  0 Loss =  21.177494725839278 Gradient_max =  0.20106035865576513 learning rate ratio =  3.523080084196787e-07\n",
      "Epoch =  987 Batch =  0 Loss =  21.177144878167606 Gradient_max =  0.20102790755121827 learning rate ratio =  3.5203330036748055e-07\n",
      "Epoch =  988 Batch =  0 Loss =  21.1767992441342 Gradient_max =  0.20099548598665007 learning rate ratio =  3.51760047919657e-07\n",
      "Epoch =  989 Batch =  0 Loss =  21.176457800825265 Gradient_max =  0.2009630938145223 learning rate ratio =  3.5148824332275514e-07\n",
      "Epoch =  990 Batch =  0 Loss =  21.176120525460576 Gradient_max =  0.20093073088814367 learning rate ratio =  3.512178788645391e-07\n",
      "Epoch =  991 Batch =  0 Loss =  21.175787395392693 Gradient_max =  0.2008983970616649 learning rate ratio =  3.5094894687377514e-07\n",
      "Epoch =  992 Batch =  0 Loss =  21.175458388106144 Gradient_max =  0.2008660921900732 learning rate ratio =  3.5068143972001717e-07\n",
      "Epoch =  993 Batch =  0 Loss =  21.17513348122895 Gradient_max =  0.20083381612923262 learning rate ratio =  3.5041534981337615e-07\n",
      "Epoch =  994 Batch =  0 Loss =  21.174812652508134 Gradient_max =  0.20080156873579932 learning rate ratio =  3.501506696043472e-07\n",
      "Epoch =  995 Batch =  0 Loss =  21.17449587982568 Gradient_max =  0.20076934986725428 learning rate ratio =  3.498873915835548e-07\n",
      "Epoch =  996 Batch =  0 Loss =  21.174183141166722 Gradient_max =  0.20073715938181197 learning rate ratio =  3.496255082816061e-07\n",
      "Epoch =  997 Batch =  0 Loss =  21.17387441466312 Gradient_max =  0.20070499713856732 learning rate ratio =  3.493650122688155e-07\n",
      "Epoch =  998 Batch =  0 Loss =  21.17356968126943 Gradient_max =  0.20067286302326395 learning rate ratio =  3.491058961550203e-07\n",
      "Epoch =  999 Batch =  0 Loss =  21.17326891946376 Gradient_max =  0.20064075689744695 learning rate ratio =  3.488481525893735e-07\n"
     ]
    }
   ],
   "source": [
    "SGD = Solver(Model, x_train, y_train, lr = 1.5e-5, batch_size = 30, num_epochs = 1000, print_every = 1000)\n",
    "SGD.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(0,SGD.num_epochs)\n",
    "plt.plot(epochs, SGD.loss_history, label = 'Loss', color = 'red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, SGD.vel_history, label = 'Velocity', color = 'blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, SGD.grad_history, label = 'Absolute Gradient', color = 'green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39874902267396406"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training_accuracy(model, x_train,y_train):\n",
    "    y_pred = model.predict(x_train)\n",
    "    y_new = y_train.reshape(y_pred.shape)\n",
    "    return np.sum(y_new == y_pred) / y_new.shape[0]\n",
    "\n",
    "print(np.sum(Model.predict(x_train)))\n",
    "training_accuracy(Model, x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.384375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_accuracy(model, x_test, y_test, mu, sigma):\n",
    "    y_pred = model.predict((x_test - mu) / sigma)\n",
    "    y_new = y_test.reshape(y_pred.shape)\n",
    "    return np.sum(y_new == y_pred) / y_new.shape[0]\n",
    "\n",
    "x_test_new = x_test\n",
    "x_test_new = x_test_new \n",
    "test_accuracy(Model, x_test_new, y_test, mu, sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8201e9342a4a492ddbd4e81efec90b2ccf0d205cda2cc39ac893f0c43374b5e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
